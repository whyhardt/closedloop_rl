{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL libraries\n",
    "sys.path.append('resources')  # add source directoy to path\n",
    "from resources import rnn, rnn_training, bandits, rnn_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6085727; Time: 18.1230s; Convergence value: 3.91e-01\n",
      "Epoch 2/5 --- Loss: 0.6095850; Time: 14.9941s; Convergence value: 1.78e-01\n",
      "Epoch 3/5 --- Loss: 0.6080438; Time: 13.7053s; Convergence value: 1.05e-01\n",
      "Epoch 4/5 --- Loss: 0.6078517; Time: 11.4109s; Convergence value: 6.60e-02\n",
      "Epoch 5/5 --- Loss: 0.6076877; Time: 13.4029s; Convergence value: 6.19e-04\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 1.3506s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.7666s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.7329s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.7352s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.9492s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.7791s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.6491s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.6835s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.7014s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5965887; Time: 0.6799s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 79.71 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4e6a552e49e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;31m# get q-values from trained rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m \u001b[0mqs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbandits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_update_dynamics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_list_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[0mlist_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[0mlist_qs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\bandits.py\u001b[0m in \u001b[0;36mget_update_dynamics\u001b[1;34m(experiment, agent)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[0mqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0mchoice_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_choice_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchoice_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\bandits.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, choice, reward)\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;31m# self.set_state(self._model.get_state(return_dict=True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, prev_state, batch_first)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[0maction_oh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_oh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "\"\"\" # train model (BASELINE)\n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 1\n",
    "ensemble = rnn_training.ensemble_types.NONE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  baseline_losses = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      baseline_losses.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "# Synthesize a dataset using the fitted network\n",
    "environment = bandits.EnvironmentBanditsDrift(0.1)\n",
    "model.set_device(torch.device('cpu'))\n",
    "model.to(torch.device('cpu'))\n",
    "rnn_agent = bandits.AgentNetwork(model, n_actions=2)\n",
    "\n",
    "# Analysis\n",
    "session_id = 0\n",
    "\n",
    "choices = experiment_list_test[session_id].choices\n",
    "rewards = experiment_list_test[session_id].rewards\n",
    "\n",
    "list_probs = []\n",
    "list_qs = []\n",
    "\n",
    "# get q-values from groundtruth\n",
    "qs_test, probs_test = bandits.get_update_dynamics(experiment_list_test[session_id], agent)\n",
    "list_probs.append(np.expand_dims(probs_test, 0))\n",
    "list_qs.append(np.expand_dims(qs_test, 0))\n",
    "\n",
    "# get q-values from trained rnn\n",
    "qs_rnn, probs_rnn = bandits.get_update_dynamics(experiment_list_test[session_id], rnn_agent)\n",
    "list_probs.append(np.expand_dims(probs_rnn, 0))\n",
    "list_qs.append(np.expand_dims(qs_rnn, 0))\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:pink', 'tab:grey']\n",
    "\n",
    "# concatenate all choice probs and q-values\n",
    "probs = np.concatenate(list_probs, axis=0)\n",
    "qs = np.concatenate(list_qs, axis=0)\n",
    "\n",
    "# normalize q-values\n",
    "def normalize(qs):\n",
    "  return (qs - np.min(qs, axis=1, keepdims=True)) / (np.max(qs, axis=1, keepdims=True) - np.min(qs, axis=1, keepdims=True))\n",
    "\n",
    "qs = normalize(qs)\n",
    "fig, axs = plt.subplots(4, 1, figsize=(20, 10))\n",
    "\n",
    "reward_probs = np.stack([experiment_list_test[session_id].timeseries[:, i] for i in range(n_actions)], axis=0)\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=reward_probs,\n",
    "    timeseries_name='Reward Probs',\n",
    "    labels=[f'Arm {a}' for a in range(n_actions)],\n",
    "    color=['tab:purple', 'tab:cyan'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[0]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=probs[:, :, 0],\n",
    "    timeseries_name='Choice Probs',\n",
    "    color=colors,\n",
    "    labels=['Ground Truth', 'RNN'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[1]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=qs[:, :, 0],\n",
    "    timeseries_name='Q-Values',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[2]),\n",
    "    )\n",
    "\n",
    "dqs_arms = normalize(-1*np.diff(qs, axis=2))\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=dqs_arms[:, :, 0],\n",
    "    timeseries_name='dQ/dActions',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[3]),\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" baseline_losses\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"Baseline\"]*len(baseline_losses)\n",
    "df[\"loss\"] = baseline_losses\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584,\n",
       " 0.5941007137298584]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6120324; Time: 40.7008s; Convergence value: 3.88e-01\n",
      "Epoch 2/5 --- Loss: 0.5564060; Time: 40.5172s; Convergence value: 2.07e-01\n",
      "Epoch 3/5 --- Loss: 0.5558216; Time: 46.0110s; Convergence value: 1.22e-01\n",
      "Epoch 4/5 --- Loss: 0.5556806; Time: 47.3550s; Convergence value: 7.72e-02\n",
      "Epoch 5/5 --- Loss: 0.5556332; Time: 46.4392s; Convergence value: 9.46e-03\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'concatenate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2296d3b8c7d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    168\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m           \u001b[0mn_steps_per_call\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m       )\n\u001b[0;32m    172\u001b[0m       \u001b[0mn2_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn_training.py\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model, dataset, optimizer, convergence_threshold, epochs, batch_size, sampling_replacement, n_submodels, ensemble_type, voting_type, evolution_interval, verbose, n_steps_per_call)\u001b[0m\n\u001b[0;32m    197\u001b[0m                         \u001b[0mys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                         \u001b[0mn_steps_per_call\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_steps_per_call\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                     )\n\u001b[0;32m    201\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn_training.py\u001b[0m in \u001b[0;36mbatch_train\u001b[1;34m(model, xs, ys, optimizer, n_steps_per_call, loss_fn, weight_reg_rnn)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;31m# predict y and compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn.py\u001b[0m in \u001b[0;36minitial_state\u001b[1;34m(self, batch_size, return_dict)\u001b[0m\n\u001b[0;32m    454\u001b[0m         \u001b[1;31m# state = [torch.concat(s, dim=1) for s in state]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[1;31m# self._state = state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    457\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn.py\u001b[0m in \u001b[0;36mset_state\u001b[1;34m(self, states)\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m                 \u001b[1;31m# if hidden state keep the state of each model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m                 \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_all_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             \u001b[0mstates_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstates_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'concatenate'"
     ]
    }
   ],
   "source": [
    "# 4 submodels\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.VOTE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n2_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n2_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f57b5e9c667b>\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m           \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[0mn_steps_per_call\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m       )\n\u001b[0m\u001b[0;32m     11\u001b[0m       \u001b[0mn2_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Synthesize a dataset using the fitted network\n",
    "environment = bandits.EnvironmentBanditsDrift(0.1)\n",
    "model.set_device(torch.device('cpu'))\n",
    "model.to(torch.device('cpu'))\n",
    "rnn_agent = bandits.AgentNetwork(model, n_actions=2)\n",
    "\n",
    "# Analysis\n",
    "session_id = 0\n",
    "\n",
    "choices = experiment_list_test[session_id].choices\n",
    "rewards = experiment_list_test[session_id].rewards\n",
    "\n",
    "list_probs = []\n",
    "list_qs = []\n",
    "\n",
    "# get q-values from groundtruth\n",
    "qs_test, probs_test = bandits.get_update_dynamics(experiment_list_test[session_id], agent)\n",
    "list_probs.append(np.expand_dims(probs_test, 0))\n",
    "list_qs.append(np.expand_dims(qs_test, 0))\n",
    "\n",
    "# get q-values from trained rnn\n",
    "qs_rnn, probs_rnn = bandits.get_update_dynamics(experiment_list_test[session_id], rnn_agent)\n",
    "list_probs.append(np.expand_dims(probs_rnn, 0))\n",
    "list_qs.append(np.expand_dims(qs_rnn, 0))\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:pink', 'tab:grey']\n",
    "\n",
    "# concatenate all choice probs and q-values\n",
    "probs = np.concatenate(list_probs, axis=0)\n",
    "qs = np.concatenate(list_qs, axis=0)\n",
    "\n",
    "# normalize q-values\n",
    "def normalize(qs):\n",
    "  return (qs - np.min(qs, axis=1, keepdims=True)) / (np.max(qs, axis=1, keepdims=True) - np.min(qs, axis=1, keepdims=True))\n",
    "\n",
    "qs = normalize(qs)\n",
    "fig, axs = plt.subplots(4, 1, figsize=(20, 10))\n",
    "\n",
    "reward_probs = np.stack([experiment_list_test[session_id].timeseries[:, i] for i in range(n_actions)], axis=0)\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=reward_probs,\n",
    "    timeseries_name='Reward Probs',\n",
    "    labels=[f'Arm {a}' for a in range(n_actions)],\n",
    "    color=['tab:purple', 'tab:cyan'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[0]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=probs[:, :, 0],\n",
    "    timeseries_name='Choice Probs',\n",
    "    color=colors,\n",
    "    labels=['Ground Truth', 'RNN'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[1]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=qs[:, :, 0],\n",
    "    timeseries_name='Q-Values',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[2]),\n",
    "    )\n",
    "\n",
    "dqs_arms = normalize(-1*np.diff(qs, axis=2))\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=dqs_arms[:, :, 0],\n",
    "    timeseries_name='dQ/dActions',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[3]),\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.588664710521698, 0.5886646509170532, 0.5886647701263428, 0.588664710521698, 0.5886646509170532, 0.588664710521698, 0.588664710521698, 0.588664710521698, 0.5886646509170532, 0.5886646509170532]\n"
     ]
    }
   ],
   "source": [
    "print(baseline_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-973a619187f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mn_trials_per_session\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_trials_per_session\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[0mn_sessions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m       device=device)\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m   dataset_test, experiment_list_test = bandits.create_dataset(\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\bandits.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(agent, environment, n_trials_per_session, n_sessions, sequence_length, stride, device)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;31m# one-hot encoding of choices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0mchoices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m     \u001b[0mys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 16 submodels\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 16\n",
    "ensemble = rnn_training.ensemble_types.VOTE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 15\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n16_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n16_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 submodels\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 32\n",
    "ensemble = rnn_training.ensemble_types.VOTE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 25\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n32_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n32_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6424130; Time: 308.1779s; Convergence value: 3.58e-01\n",
      "Epoch 2/5 --- Loss: 0.5910122; Time: 362.1660s; Convergence value: 1.91e-01\n",
      "Epoch 3/5 --- Loss: 0.5868228; Time: 362.2209s; Convergence value: 1.14e-01\n",
      "Epoch 4/5 --- Loss: 0.5854608; Time: 348.2068s; Convergence value: 7.26e-02\n",
      "Epoch 5/5 --- Loss: 0.5849690; Time: 321.2144s; Convergence value: 1.00e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 2.0071s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.7294s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6976s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152542; Time: 0.7176s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6984s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6662s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6516s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6708s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6267s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6152543; Time: 0.6397s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 1754.60 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # 32 submodels, ensemble average\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 32\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n32_eA_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n32_eA_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-40b5db348e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# get q-values from trained rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mqs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_rnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbandits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_update_dynamics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_list_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_agent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mlist_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mlist_qs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqs_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\bandits.py\u001b[0m in \u001b[0;36mget_update_dynamics\u001b[1;34m(experiment, agent)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[0mqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0mchoice_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_choice_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchoice_probs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\bandits.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, choice, reward)\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;31m# self.set_state(self._model.get_state(return_dict=True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\Desktop\\Uni\\Sync\\8_Semester\\Lab rotation modeling\\closedloop_rl\\resources\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, prev_state, batch_first)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[0maction_oh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_oh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tensors used as indices must be long, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "# Synthesize a dataset using the fitted network\n",
    "environment = bandits.EnvironmentBanditsDrift(0.1)\n",
    "model.set_device(torch.device('cpu'))\n",
    "model.to(torch.device('cpu'))\n",
    "rnn_agent = bandits.AgentNetwork(model, n_actions=2)\n",
    "\n",
    "# Analysis\n",
    "session_id = 0\n",
    "\n",
    "choices = experiment_list_test[session_id].choices\n",
    "rewards = experiment_list_test[session_id].rewards\n",
    "\n",
    "list_probs = []\n",
    "list_qs = []\n",
    "\n",
    "# get q-values from groundtruth\n",
    "qs_test, probs_test = bandits.get_update_dynamics(experiment_list_test[session_id], agent)\n",
    "list_probs.append(np.expand_dims(probs_test, 0))\n",
    "list_qs.append(np.expand_dims(qs_test, 0))\n",
    "\n",
    "# get q-values from trained rnn\n",
    "qs_rnn, probs_rnn = bandits.get_update_dynamics(experiment_list_test[session_id], rnn_agent)\n",
    "list_probs.append(np.expand_dims(probs_rnn, 0))\n",
    "list_qs.append(np.expand_dims(qs_rnn, 0))\n",
    "\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:pink', 'tab:grey']\n",
    "\n",
    "# concatenate all choice probs and q-values\n",
    "probs = np.concatenate(list_probs, axis=0)\n",
    "qs = np.concatenate(list_qs, axis=0)\n",
    "\n",
    "# normalize q-values\n",
    "def normalize(qs):\n",
    "  return (qs - np.min(qs, axis=1, keepdims=True)) / (np.max(qs, axis=1, keepdims=True) - np.min(qs, axis=1, keepdims=True))\n",
    "\n",
    "qs = normalize(qs)\n",
    "fig, axs = plt.subplots(4, 1, figsize=(20, 10))\n",
    "\n",
    "reward_probs = np.stack([experiment_list_test[session_id].timeseries[:, i] for i in range(n_actions)], axis=0)\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=reward_probs,\n",
    "    timeseries_name='Reward Probs',\n",
    "    labels=[f'Arm {a}' for a in range(n_actions)],\n",
    "    color=['tab:purple', 'tab:cyan'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[0]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=probs[:, :, 0],\n",
    "    timeseries_name='Choice Probs',\n",
    "    color=colors,\n",
    "    labels=['Ground Truth', 'RNN'],\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[1]),\n",
    "    )\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=qs[:, :, 0],\n",
    "    timeseries_name='Q-Values',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[2]),\n",
    "    )\n",
    "\n",
    "dqs_arms = normalize(-1*np.diff(qs, axis=2))\n",
    "\n",
    "bandits.plot_session(\n",
    "    compare=True,\n",
    "    choices=choices,\n",
    "    rewards=rewards,\n",
    "    timeseries=dqs_arms[:, :, 0],\n",
    "    timeseries_name='dQ/dActions',\n",
    "    color=colors,\n",
    "    binary=not non_binary_reward,\n",
    "    fig_ax=(fig, axs[3]),\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n32_eA_rF_vMedian\"]*len(n32_eA_loss)\n",
    "df[\"loss\"] = n32_eA_loss\n",
    "\n",
    "df.to_csv(\"losses.csv\", index=False) \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6656887; Time: 149.2490s; Convergence value: 3.34e-01\n",
      "Epoch 2/5 --- Loss: 0.5774788; Time: 170.3928s; Convergence value: 2.00e-01\n",
      "Epoch 3/5 --- Loss: 0.5747513; Time: 179.9744s; Convergence value: 1.20e-01\n",
      "Epoch 4/5 --- Loss: 0.5744476; Time: 167.1248s; Convergence value: 7.62e-02\n",
      "Epoch 5/5 --- Loss: 0.5742643; Time: 156.3004s; Convergence value: 1.55e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 1.6211s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.4725s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.5172s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.5093s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.7930s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.7204s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.9073s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.7242s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972804; Time: 0.7155s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5972803; Time: 0.8151s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 838.32 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # 16 submodels, ensemble average\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 16\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n16_eA_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n16_eA_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n16_eA_loss\"]*len(n16_eA_loss)\n",
    "df[\"loss\"] = n16_eA_loss\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.5625863; Time: 40.1743s; Convergence value: 4.37e-01\n",
      "Epoch 2/5 --- Loss: 0.5621565; Time: 43.2809s; Convergence value: 1.99e-01\n",
      "Epoch 3/5 --- Loss: 0.5623043; Time: 43.7317s; Convergence value: 1.17e-01\n",
      "Epoch 4/5 --- Loss: 0.5623129; Time: 38.9261s; Convergence value: 7.30e-02\n",
      "Epoch 5/5 --- Loss: 0.5622482; Time: 42.4550s; Convergence value: 1.28e-04\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5826510; Time: 1.1511s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.8015s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.4829s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.4844s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.5312s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826510; Time: 0.5440s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.5144s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826510; Time: 0.5208s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.5157s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5826511; Time: 0.5887s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 215.72 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # 4 submodels, ensemble average\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMedian_loss\"]*len(n4_eA_loss)\n",
    "df[\"loss\"] = n4_eA_loss\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False) \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6473184; Time: 38.7940s; Convergence value: 3.53e-01\n",
      "Epoch 2/5 --- Loss: 0.5104391; Time: 49.3358s; Convergence value: 2.35e-01\n",
      "Epoch 3/5 --- Loss: 0.5069841; Time: 44.6704s; Convergence value: 1.41e-01\n",
      "Epoch 4/5 --- Loss: 0.5057298; Time: 41.4925s; Convergence value: 9.06e-02\n",
      "Epoch 5/5 --- Loss: 0.5052085; Time: 41.6943s; Convergence value: 2.41e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 1.5447s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 0.6642s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 0.6583s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 0.5843s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 1.0439s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006865; Time: 0.7657s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006865; Time: 0.5783s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 0.7070s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 0.7821s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6006864; Time: 1.1556s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 225.51 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, MEAN\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_mean_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_mean_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_mean_loss\"]*len(n4_eA_mean_loss)\n",
    "df[\"loss\"] = n4_eA_mean_loss\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacement = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.9813210; Time: 44.3188s; Convergence value: 1.87e-02\n",
      "Epoch 2/5 --- Loss: 0.5939740; Time: 36.5132s; Convergence value: 2.20e-01\n",
      "Epoch 3/5 --- Loss: 0.6020821; Time: 35.0467s; Convergence value: 1.37e-01\n",
      "Epoch 4/5 --- Loss: 0.6115658; Time: 44.1253s; Convergence value: 9.46e-02\n",
      "Epoch 5/5 --- Loss: 0.6077671; Time: 35.1974s; Convergence value: 7.03e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 1.0227s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5679s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5664s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5662s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5665s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.6237s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5756s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5637s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.7334s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5912160; Time: 0.5686s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 202.42 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" # 4 submodels, ensemble average, replacement true\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = True\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rT_vA_loss = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rT_vA_loss.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n4_eA_rT_vA_loss\n",
    "\n",
    "\"\"\" df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rT_vA_loss\"]*len(n4_eA_rT_vA_loss)\n",
    "df[\"loss\"] = n4_eA_rT_vA_loss\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False) \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# until HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.7806702; Time: 156.4051s; Convergence value: 2.19e-01\n",
      "Epoch 2/5 --- Loss: 0.6086048; Time: 195.4610s; Convergence value: 1.94e-01\n",
      "Epoch 3/5 --- Loss: 0.6179161; Time: 174.1217s; Convergence value: 1.20e-01\n",
      "Epoch 4/5 --- Loss: 0.6172372; Time: 174.7405s; Convergence value: 7.76e-02\n",
      "Epoch 5/5 --- Loss: 0.6013812; Time: 169.7018s; Convergence value: 3.62e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 1.4950s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.9518s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.7560s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.8240s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.6556s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.7185s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.6249s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.8037s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 1.0287s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5916854; Time: 0.6777s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 887.28 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'losses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-4c3049555ffa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"losses.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\meril\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\meril\\miniconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'losses.csv'"
     ]
    }
   ],
   "source": [
    "# 16 submodels, ensemble average, replacement true\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = True\n",
    "n_submodels = 16\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n16_eA_rT_vA = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n16_eA_rT_vA.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n16_eA_rT_vA\"]*len(n16_eA_rT_vA)\n",
    "df[\"loss\"] = n16_eA_rT_vA\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.7097447; Time: 388.3936s; Convergence value: 2.90e-01\n",
      "Epoch 2/5 --- Loss: 0.5554522; Time: 376.2014s; Convergence value: 2.16e-01\n",
      "Epoch 3/5 --- Loss: 0.5579701; Time: 326.1727s; Convergence value: 1.30e-01\n",
      "Epoch 4/5 --- Loss: 0.5586378; Time: 348.1144s; Convergence value: 8.36e-02\n",
      "Epoch 5/5 --- Loss: 0.5581956; Time: 332.8312s; Convergence value: 2.66e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 1.2164s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.6356s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.5270s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050162; Time: 0.8517s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.5345s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.5191s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.4849s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.5497s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050162; Time: 0.5339s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6050161; Time: 0.5658s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 1793.43 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 32 submodels, ensemble average, replacement true, Mmedian\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = True\n",
    "n_submodels = 32\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 256\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n32_eA_rT_vMed = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n32_eA_rT_vMed.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n32_eA_rT_vMed\"]*len(n32_eA_rT_vMed)\n",
    "df[\"loss\"] = n32_eA_rT_vMed\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.7676185; Time: 29.5787s; Convergence value: 2.32e-01\n",
      "Epoch 2/5 --- Loss: 0.6138930; Time: 29.1224s; Convergence value: 1.89e-01\n",
      "Epoch 3/5 --- Loss: 0.6126850; Time: 28.9014s; Convergence value: 1.14e-01\n",
      "Epoch 4/5 --- Loss: 0.6008949; Time: 28.5122s; Convergence value: 7.72e-02\n",
      "Epoch 5/5 --- Loss: 0.5930960; Time: 28.3805s; Convergence value: 3.18e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.7832s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5164s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5945s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5198s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5297s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.4998s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029520; Time: 0.6665s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5694s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5288s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6029521; Time: 0.5355s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 150.78 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, replacement false, n sessions = 32\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 32\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rF_vMed_s32 = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rF_vMed_s32.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMed_s32\"]*len(n4_eA_rF_vMed_s32)\n",
    "df[\"loss\"] = n4_eA_rF_vMed_s32\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.5211298; Time: 33.8978s; Convergence value: 4.79e-01\n",
      "Epoch 2/5 --- Loss: 0.5298360; Time: 29.3004s; Convergence value: 2.22e-01\n",
      "Epoch 3/5 --- Loss: 0.5243396; Time: 34.9633s; Convergence value: 1.33e-01\n",
      "Epoch 4/5 --- Loss: 0.5216225; Time: 29.3338s; Convergence value: 8.42e-02\n",
      "Epoch 5/5 --- Loss: 0.5190710; Time: 29.3163s; Convergence value: 4.28e-03\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.7667s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5252s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5513s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5487s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5500s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5151s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5470s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5468s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5570s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6378747; Time: 0.5416s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 162.96 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, replacement false, n sessions = 64\n",
    "\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 64\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rF_vMed_s64 = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rF_vMed_s64.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMed_s64\"]*len(n4_eA_rF_vMed_s64)\n",
    "df[\"loss\"] = n4_eA_rF_vMed_s64\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.5421701; Time: 32.4095s; Convergence value: 4.58e-01\n",
      "Epoch 2/5 --- Loss: 0.5430398; Time: 30.6045s; Convergence value: 2.09e-01\n",
      "Epoch 3/5 --- Loss: 0.5407185; Time: 31.0489s; Convergence value: 1.23e-01\n",
      "Epoch 4/5 --- Loss: 0.5400136; Time: 30.7992s; Convergence value: 7.74e-02\n",
      "Epoch 5/5 --- Loss: 0.5396372; Time: 32.2932s; Convergence value: 9.82e-04\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.8164s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863686; Time: 0.5332s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863686; Time: 0.5687s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5664s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863686; Time: 0.6195s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5226s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5246s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5509s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5495s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5863687; Time: 0.5333s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 163.52 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, replacement false, n sessions = 128\n",
    "\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 200\n",
    "n_sessions = 128\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rF_vMed_s128 = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rF_vMed_s128.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMed_s128\"]*len(n4_eA_rF_vMed_s128)\n",
    "df[\"loss\"] = n4_eA_rF_vMed_s128\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# run til HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 1.0352575; Time: 7.7921s; Convergence value: 3.53e-02\n",
      "Epoch 2/5 --- Loss: 0.6572930; Time: 7.1495s; Convergence value: 2.22e-01\n",
      "Epoch 3/5 --- Loss: 0.5730930; Time: 6.8980s; Convergence value: 1.69e-01\n",
      "Epoch 4/5 --- Loss: 0.5614052; Time: 6.7220s; Convergence value: 1.17e-01\n",
      "Epoch 5/5 --- Loss: 0.5523785; Time: 6.8675s; Convergence value: 8.80e-02\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.6678745; Time: 0.6247s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5222s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5353s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5329s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5697s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5316s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678745; Time: 0.5163s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5667s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678746; Time: 0.5142s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.6678745; Time: 0.5357s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 41.03 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, replacement false, n sessions = 128, trials 50\n",
    "\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 50 #200\n",
    "n_sessions = 128\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rF_vMed_s128_t50 = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rF_vMed_s128_t50.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMed_s128_t50\"]*len(n4_eA_rF_vMed_s128_t50)\n",
    "df[\"loss\"] = n4_eA_rF_vMed_s128_t50\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically generated name for model parameter file: params/params_rnn_b3_f01.pkl.\n",
      "Training the hybrid RNN...\n",
      "Epoch 1/5 --- Loss: 0.6090691; Time: 6.9239s; Convergence value: 3.91e-01\n",
      "Epoch 2/5 --- Loss: 0.5869692; Time: 6.8027s; Convergence value: 1.90e-01\n",
      "Epoch 3/5 --- Loss: 0.5752981; Time: 6.6552s; Convergence value: 1.16e-01\n",
      "Epoch 4/5 --- Loss: 0.5748299; Time: 6.6199s; Convergence value: 7.35e-02\n",
      "Epoch 5/5 --- Loss: 0.5749742; Time: 6.6964s; Convergence value: 6.46e-03\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "Validating the trained hybrid RNN on a test dataset...\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.6687s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.5791s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.6006s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.6344s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.6001s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.5785s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737438; Time: 0.5638s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.5703s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.5964s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Epoch 1/1 --- Loss: 0.5737439; Time: 0.6042s; Convergence value: nan\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "Training took 39.83 seconds.\n",
      "Saved RNN parameters to file params/params_rnn_b3_f01.pkl.\n"
     ]
    }
   ],
   "source": [
    "# 4 submodels, ensemble average, replacement false, n sessions = 64, 50 trials\n",
    "\n",
    "\n",
    "# train model \n",
    "train = True\n",
    "checkpoint = False\n",
    "data = False\n",
    "\n",
    "path_data = 'data/dataset_train.pkl'\n",
    "params_path = 'params/params_lstm_b3.pkl'  # overwritten if data is False (adapted to the ground truth model)\n",
    "\n",
    "# rnn parameters\n",
    "hidden_size = 4\n",
    "last_output = False\n",
    "last_state = False\n",
    "use_lstm = False\n",
    "\n",
    "# ensemble parameters\n",
    "evolution_interval = None\n",
    "sampling_replacement = False\n",
    "n_submodels = 4\n",
    "ensemble = rnn_training.ensemble_types.AVERAGE\n",
    "voting_type = rnn.EnsembleRNN.MEDIAN  # necessary if ensemble==True\n",
    "\n",
    "\n",
    "# training parameters\n",
    "epochs = 5\n",
    "n_steps_per_call = 16  # None for full sequence\n",
    "batch_size = None  # None for one batch per epoch\n",
    "learning_rate = 1e-2\n",
    "convergence_threshold = 1e-6\n",
    "\n",
    "\n",
    "# ground truth parameters\n",
    "gen_alpha = .25\n",
    "gen_beta = 3\n",
    "forget_rate = 0.1  # possible values: 0., 0.1\n",
    "perseverance_bias = 0.\n",
    "correlated_update = False  # possible values: True, False\n",
    "\n",
    "\n",
    "# environment parameters\n",
    "n_actions = 2\n",
    "sigma = 0.1\n",
    "n_trials_per_session = 50 #200\n",
    "n_sessions = 64\n",
    "correlated_reward = False\n",
    "non_binary_reward = False\n",
    "\n",
    "\n",
    "# tracked variables in the RNN\n",
    "x_train_list = ['xQf','xQr', 'xQc']\n",
    "control_list = ['ca','ca[k-1]', 'cr']\n",
    "sindy_feature_list = x_train_list + control_list\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "if not data:\n",
    "  # setup\n",
    "  environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_reward=non_binary_reward, correlated_reward=correlated_reward)\n",
    "  agent = bandits.AgentQ(gen_alpha, gen_beta, n_actions, forget_rate, perseverance_bias, correlated_update)  \n",
    "\n",
    "  dataset_train, experiment_list_train = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=n_trials_per_session,\n",
    "      n_sessions=n_sessions,\n",
    "      device=device)\n",
    "\n",
    "  dataset_test, experiment_list_test = bandits.create_dataset(\n",
    "      agent=agent,\n",
    "      environment=environment,\n",
    "      n_trials_per_session=200,\n",
    "      n_sessions=1024,\n",
    "      device=device)\n",
    "  \n",
    "  params_path = rnn_utils.parameter_file_naming(\n",
    "      'params/params',\n",
    "      use_lstm,\n",
    "      last_output,\n",
    "      last_state,\n",
    "      gen_beta,\n",
    "      forget_rate,\n",
    "      perseverance_bias,\n",
    "      correlated_update,\n",
    "      non_binary_reward,\n",
    "      verbose=True,\n",
    "  )\n",
    "  \n",
    "else:\n",
    "  # load data\n",
    "  with open(path_data, 'rb') as f:\n",
    "      dataset_train = pickle.load(f)\n",
    "\n",
    "if ensemble > -1 and n_submodels == 1:\n",
    "  Warning('Ensemble is actived but n_submodels is set to 1. Deactivating ensemble...')\n",
    "  ensemble = rnn_training.ensemble_types.NONE\n",
    "\n",
    "# define model\n",
    "if use_lstm:\n",
    "  model = rnn.LSTM(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      device=device,\n",
    "      ).to(device)\n",
    "else:\n",
    "  model = [rnn.RLRNN(\n",
    "      n_actions=n_actions, \n",
    "      hidden_size=hidden_size, \n",
    "      init_value=0.5,\n",
    "      last_output=last_output,\n",
    "      last_state=last_state,\n",
    "      device=device,\n",
    "      list_sindy_signals=sindy_feature_list,\n",
    "      ).to(device)\n",
    "           for _ in range(n_submodels)]\n",
    "\n",
    "optimizer_rnn = [torch.optim.Adam(m.parameters(), lr=learning_rate) for m in model]\n",
    "\n",
    "if checkpoint:\n",
    "    # load trained parameters\n",
    "    state_dict = torch.load(params_path, map_location=torch.device('cpu'))\n",
    "    state_dict_model = state_dict['model']\n",
    "    state_dict_optimizer = state_dict['optimizer']\n",
    "    if isinstance(state_dict_model, dict):\n",
    "      for m, o in zip(model, optimizer_rnn):\n",
    "        m.load_state_dict(state_dict_model)\n",
    "        o.load_state_dict(state_dict_optimizer)\n",
    "    elif isinstance(state_dict_model, list):\n",
    "        print('Loading ensemble model...')\n",
    "        for i, state_dict_model_i, state_dict_optim_i in zip(range(n_submodels), state_dict_model, state_dict_optimizer):\n",
    "            model[i].load_state_dict(state_dict_model_i)\n",
    "            optimizer_rnn[i].load_state_dict(state_dict_optim_i)\n",
    "        rnn = rnn.EnsembleRNN(model, voting_type=voting_type)\n",
    "    print('Loaded parameters.')\n",
    "\n",
    "if train:\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  #Fit the hybrid RNN\n",
    "  print('Training the hybrid RNN...')\n",
    "  model, optimizer_rnn, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      optimizer=optimizer_rnn,\n",
    "      convergence_threshold=convergence_threshold,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      sampling_replacement=sampling_replacement,\n",
    "      evolution_interval=evolution_interval,\n",
    "      n_steps_per_call=n_steps_per_call,\n",
    "  )\n",
    "  \n",
    "\n",
    "  n4_eA_rF_vMed_s64_t50 = []\n",
    "\n",
    "  # validate model\n",
    "  print('\\nValidating the trained hybrid RNN on a test dataset...')\n",
    "\n",
    "  for _ in range(10):\n",
    "    with torch.no_grad():\n",
    "      model, _, loss = rnn_training.fit_model(\n",
    "          model=model,\n",
    "          dataset=dataset_test,\n",
    "          n_steps_per_call=1,\n",
    "      )\n",
    "      n4_eA_rF_vMed_s64_t50.append(float(loss))\n",
    "\n",
    "\n",
    "  print(f'Training took {time.time() - start_time:.2f} seconds.')\n",
    "  \n",
    "\n",
    "  # save trained parameters  \n",
    "  state_dict = {\n",
    "    'model': model.state_dict() if isinstance(model, torch.nn.Module) else [model_i.state_dict() for model_i in model],\n",
    "    'optimizer': optimizer_rnn.state_dict() if isinstance(optimizer_rnn, torch.optim.Adam) else [optim_i.state_dict() for optim_i in optimizer_rnn],\n",
    "  }\n",
    "  torch.save(state_dict, params_path)\n",
    "  \n",
    "  print(f'Saved RNN parameters to file {params_path}.')\n",
    "\n",
    "else:\n",
    "  model, _, _ = rnn_training.fit_model(\n",
    "      model=model,\n",
    "      dataset=dataset_train,\n",
    "      epochs=0,\n",
    "      n_submodels=n_submodels,\n",
    "      ensemble_type=ensemble,\n",
    "      voting_type=voting_type,\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'loss'])\n",
    "\n",
    "df[\"model\"] = [\"n4_eA_rF_vMed_s64_t50\"]*len(n4_eA_rF_vMed_s64_t50)\n",
    "df[\"loss\"] = n4_eA_rF_vMed_s64_t50\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"losses.csv\")\n",
    "losses = df1.append(df)\n",
    "\n",
    "losses.to_csv(\"losses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
