{"cells":[{"cell_type":"markdown","metadata":{"id":"LwfT57-uJIt9"},"source":["## Installation and imports"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"zDN04KYnHMmI","metadata":{}},"outputs":[{"name":"stdout","output_type":"stream","text":["Not on Google Colab. Assuming you already installed the required packages.\n"]}],"source":["#@title Install required packages.\n","try:\n","    from google.colab import files  # checks if you are on google colab\n","    !rm -rf CogModelingRNNsTutorial\n","    !git clone https://github.com/whyhardt/CogModelingRNN.git\n","    %pip install -e CogModelingRNN/CogModelingRNNsTutorial\n","    !cp CogModelingRNN/CogModelingRNNsTutorial/*py CogModelingRNN\n","    %pip install pysindy\n","    _ON_COLAB = True\n","except:\n","    print('Not on Google Colab. Assuming you already installed the required packages.')"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"lVdDzYwVHbdb","metadata":{}},"outputs":[],"source":["#@title Import libraries\n","import sys\n","import os\n","import warnings\n","from typing import Callable, Tuple, Iterable, Union\n","\n","import matplotlib.pyplot as plt\n","from sympy.parsing.sympy_parser import parse_expr\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as st\n","import pickle\n","\n","# deepmind related libraries\n","import haiku as hk\n","import jax\n","import jax.numpy as jnp\n","import optax\n","\n","import pysindy as ps\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# RL libraries\n","sys.path.append('resources')  # add source directoy to path\n","from resources import bandits, hybrnn, hybrnn_forget, rnn_utils"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"0_eVhrNccDV7","metadata":{}},"outputs":[],"source":["#@title make update rule of Q-/SINDyNetwork-Agents adjustable and make values of RNN-Agent visible\n","\n","class AgentQuadQ(bandits.AgentQ):\n","  \n","  def __init__(\n","      self,\n","      alpha: float=0.2,\n","      beta: float=3.,\n","      n_actions: int=2,\n","      forgetting_rate: float=0.,\n","      perseveration_bias: float=0.,\n","      ):\n","    super().__init__(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n","  \n","  def update(self,\n","            choice: int,\n","            reward: float):\n","    \"\"\"Update the agent after one step of the task.\n","\n","    Args:\n","      choice: The choice made by the agent. 0 or 1\n","      reward: The reward received by the agent. 0 or 1\n","    \"\"\"\n","    \n","    # Decay q-values toward the initial value.\n","    self._q = (1-self._forgetting_rate) * self._q + self._forgetting_rate * self._q_init\n","\n","    # Update chosen q for chosen action with observed reward.\n","    self._q[choice] = self._q[choice] - self._alpha * self._q[choice]**2 + self._alpha * reward\n","\n","\n","class AgentSindy(bandits.AgentQ):\n","\n","  def __init__(\n","      self,\n","      alpha: float=0.2,\n","      beta: float=3.,\n","      n_actions: int=2,\n","      forgetting_rate: float=0.,\n","      perservation_bias: float=0.,):\n","    super().__init__(alpha, beta, n_actions, forgetting_rate, perservation_bias)\n","\n","    self._update_rule = lambda q, choice, reward: (1 - self._alpha) * q[choice] + self._alpha * reward\n","    self._update_rule_formula = None\n","\n","  def set_update_rule(self, update_rule: callable, update_rule_formula: str=None):\n","    self._update_rule=update_rule\n","    self._update_rule_formula=update_rule_formula\n","\n","  @property\n","  def update_rule(self):\n","    if self._update_rule_formula is not None:\n","      return self._update_rule_formula\n","    else:\n","      return f'{self._update_rule}'\n","\n","  def update(self, choice: int, reward: int):\n","\n","    for c in range(self._n_actions):\n","      self._q[c] = self._update_rule(self._q[c], int(c==choice), reward)\n","\n","\n","class AgentNetwork_VisibleState(bandits.AgentNetwork):\n","\n","  def __init__(self,\n","               make_network: Callable[[], hk.RNNCore],\n","               params: hk.Params,\n","               n_actions: int = 2,\n","               state_to_numpy: bool = False,\n","               habit=False):\n","    super().__init__(make_network=make_network, params=params, n_actions=n_actions, state_to_numpy=state_to_numpy)\n","    self.habit = habit\n","\n","  @property\n","  def q(self):\n","    if self.habit:\n","      return self._state[-2].reshape(-1) +  self._state[-1].reshape(-1)\n","    else:\n","      return self._state[-1].reshape(-1)\n","\n","dict_agents = {\n","    'basic': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: bandits.AgentQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias),\n","    'quad_q': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: AgentQuadQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n","}"]},{"cell_type":"code","execution_count":4,"metadata":{"metadata":{}},"outputs":[],"source":["def get_q(experiment: bandits.BanditSession, agent: Union[bandits.AgentQ, bandits.AgentNetwork, AgentSindy]):\n","  \"\"\"Compute Q-Values of a specific agent for a specific experiment.\n","\n","  Args:\n","      experiment (bandits.BanditSession): _description_\n","      agent (_type_): _description_\n","\n","  Returns:\n","      _type_: _description_\n","  \"\"\"\n","  \n","  choices = np.expand_dims(experiment.choices, 1)\n","  rewards = np.expand_dims(experiment.rewards, 1)\n","  qs = np.zeros((experiment.choices.shape[0], agent._n_actions))\n","  choice_probs = np.zeros((experiment.choices.shape[0], agent._n_actions))\n","  \n","  agent.new_sess()\n","  \n","  for trial in range(experiment.choices.shape[0]):\n","    qs[trial] = agent.q\n","    choice_probs[trial] = agent.get_choice_probs()\n","    agent.update(int(choices[trial]), float(rewards[trial]))\n","    \n","  return qs, choice_probs\n","\n","\n","def parse_equation_for_sympy(eq):\n","    # replace all blank spaces with '*' where necessary\n","    # only between number and letter in exactly this order\n","    blanks = [i for i, ltr in enumerate(eq) if ltr == ' ']\n","    for blank in blanks:\n","        if (eq[blank+1].isalpha() or eq[blank-1].isdigit()) and (eq[blank+1].isalpha() or eq[blank+1].isdigit()):\n","            eq = eq[:blank] + '*' + eq[blank+1:]\n","    \n","    # replace all '^' with '**'\n","    eq = eq.replace('^', '**')\n","    \n","    # remove all [k]\n","    eq = eq.replace('[k]', '')\n","\n","    return eq\n","\n","def make_sindy_data(\n","    dataset,\n","    agent: bandits.AgentQ,\n","    sessions=-1,\n","    get_choices=True,\n","    # keep_sessions=False,\n","    ):\n","\n","  # Get training data for SINDy\n","  # put all relevant signals in x_train\n","\n","  if not isinstance(sessions, Iterable) and sessions == -1:\n","    # use all sessions\n","    sessions = np.arange(len(dataset))\n","  else:\n","    # use only the specified sessions\n","    sessions = np.array(sessions)\n","    \n","  if get_choices:\n","    n_control = 2\n","  else:\n","    n_control = 1\n","  \n","  # if keep_sessions:\n","  #   # concatenate all sessions along the trial dimensinon -> shape: (n_trials, n_sessions, n_features)\n","  #   choices = np.expand_dims(np.stack([dataset[i].choices for i in sessions], axis=1), -1)\n","  #   rewards = np.expand_dims(np.stack([dataset[i].rewards for i in sessions], axis=1), -1)\n","  #   qs = np.stack([dataset[i].q for i in sessions], axis=1)\n","  # else:\n","  # concatenate all sessions along the trial dimensinon -> shape: (n_trials*n_sessions, n_features)\n","  # choices = np.expand_dims(np.concatenate([dataset[i].choices for i in sessions], axis=0), -1)\n","  # rewards = np.expand_dims(np.concatenate([dataset[i].rewards for i in sessions], axis=0), -1)\n","  # qs = np.concatenate([dataset[i].q for i in sessions], axis=0)\n","  \n","  choices = np.stack([dataset[i].choices for i in sessions], axis=0)\n","  rewards = np.stack([dataset[i].rewards for i in sessions], axis=0)\n","  qs = np.stack([dataset[i].q for i in sessions], axis=0)\n","  \n","  if not get_choices:\n","    raise NotImplementedError('Only get_choices=True is implemented right now.')\n","    n_sessions = qs.shape[0]\n","    n_trials = qs.shape[1]*qs.shape[2]\n","    qs_all = np.zeros((n_sessions, n_trials))\n","    r_all = np.zeros((n_sessions, n_trials))\n","    c_all = None\n","    # concatenate the data of all arms into one array for more training data\n","    index_end_last_arm = 0\n","    for index_arm in range(agent._n_actions):\n","      index = np.where(choices==index_arm)[0]\n","      r_all[index_end_last_arm:index_end_last_arm+len(index)] = rewards[index]\n","      qs_all[index_end_last_arm:index_end_last_arm+len(index)] = qs[index, index_arm].reshape(-1, 1)\n","      index_end_last_arm += len(index)\n","  else:\n","    choices_oh = np.zeros((len(sessions), choices.shape[1], agent._n_actions))\n","    for sess in sessions:\n","      # one-hot encode choices\n","      choices_oh[sess] = np.eye(agent._n_actions)[choices[sess]]\n","      # add choices as control parameter; no sorting required then\n","      # qs_all = np.concatenate([qs[sess, :, i] for i in range(agent._n_actions)], axis=1)\n","      # c_all = np.concatenate([choices[:, sess, i] for i in range(agent._n_actions)], axis=1)\n","      # r_all = np.concatenate([rewards for _ in range(agent._n_actions)], axis=1)\n","      # concatenate all qs values of one sessions along the trial dimension\n","      qs_all = np.concatenate([np.stack([np.expand_dims(qs_sess[:, i], axis=-1) for i in range(agent._n_actions)], axis=0) for qs_sess in qs], axis=0)\n","      c_all = np.concatenate([np.stack([c_sess[:, i] for i in range(agent._n_actions)], axis=0) for c_sess in choices_oh], axis=0)\n","      r_all = np.concatenate([np.stack([r_sess for _ in range(agent._n_actions)], axis=0) for r_sess in rewards], axis=0)\n","  \n","  # get observed dynamics\n","  x_train = qs_all\n","  feature_names = ['q']\n","\n","  # get control\n","  control_names = []\n","  control = np.zeros((*x_train.shape[:-1], n_control))\n","  if get_choices:\n","    control[:, :, 0] = c_all\n","    control_names += ['c']\n","  control[:, :, n_control-1] = r_all\n","  control_names += ['r']\n","  \n","  feature_names += control_names\n","  \n","  print(f'Shape of Q-Values is: {x_train.shape}')\n","  print(f'Shape of control parameters is: {control.shape}')\n","  print(f'Feature names are: {feature_names}')\n","  \n","  # make x_train and control sequences instead of arrays\n","  x_train = [x_train_sess for x_train_sess in x_train]\n","  control = [control_sess for control_sess in control]\n"," \n","  return x_train, control, feature_names\n"]},{"cell_type":"markdown","metadata":{"id":"rCHCHSQbcJjU"},"source":["# RNN Reinforcement Learning"]},{"cell_type":"markdown","metadata":{"id":"Ca6uMC-Pglux"},"source":["## Set up agent and generate training data"]},{"cell_type":"code","execution_count":5,"metadata":{"cellView":"form","id":"hgqxccJZhT6d","metadata":{}},"outputs":[],"source":["#@title Select dataset type.\n","#@markdown ## Select dataset:\n","\n","dataset_type = 'synt'  #@param ['synt', 'real']\n","\n","#@markdown Set up parameters for synthetic data generation:\n","if dataset_type == 'synt':\n","    # agent parameters\n","    agent_kw = 'basic'  #@param ['basic', 'quad_q'] \n","    gen_alpha = .25 #@param\n","    gen_beta = 3 #@param\n","    forgetting_rate = 0 #@param\n","    perseveration_bias = 0.  #@param\n","    # environment parameters\n","    non_binary_reward = False #@param\n","    n_actions = 2 #@param\n","    sigma = .1  #@param\n","    \n","    # experiement parameters\n","    n_trials_per_session = 200  #@param\n","    n_sessions = 220  #@param\n","    \n","    # setup\n","    environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=n_actions, non_binary_rewards=non_binary_reward)\n","    agent = dict_agents[agent_kw](gen_alpha, gen_beta, n_actions, forgetting_rate, perseveration_bias)  \n","  \n","    dataset_train, experiment_list_train = bandits.create_dataset(\n","        agent=agent,\n","        environment=environment,\n","        n_trials_per_session=n_trials_per_session,\n","        n_sessions=n_sessions)\n","\n","    dataset_test, experiment_list_test = bandits.create_dataset(\n","        agent=agent,\n","        environment=environment,\n","        n_trials_per_session=n_trials_per_session,\n","        n_sessions=n_sessions)\n","\n","#@markdown Set up parameters for loading rat data from Miller et al 2019.\n","elif dataset_type == 'real':\n","    # TODO: ys are not the rewards but the following choices!!!!\n","    raise NotImplementedError('This is not implemented yet.')\n","\n","    path = 'data/bahrami_100.csv'\n","    data = pd.read_csv(path)\n","    xs = data['action'].values\n","    ys = data['reward'].values\n","    episodes = np.unique(data['participant_id'].values)\n","    # reshape xs and ys to be (n_trials_per_episode, n_episodes, 1). Take the variable episodes as the index for the dim 'n_episodes'\n","    train_test_ratio = 0.8\n","    n_episodes_train = int(len(episodes)*train_test_ratio)\n","    n_episodes_test = len(episodes) - n_episodes_train\n","\n","    xs = xs.reshape(-1, len(episodes), 1)\n","    ys = ys.reshape(-1, len(episodes), 1)\n","    \n","    # one-hot encode xs\n","    xs = jax.nn.one_hot(xs[:, :, 0], num_classes=int(np.max(np.unique(xs[:, 0, 0])+1)))\n","    # delay xs by one time step to have previous choices\n","    xs = np.concatenate((np.zeros((1, *xs.shape[1:])), xs[:-1, :, :]), axis=0)\n","    # add one-time-step delayed reward as feature to xs\n","    reward_delayed = np.concatenate((np.zeros((1, *ys.shape[1:])), ys[:-1, :, :]), axis=0)\n","    xs = np.concatenate((xs, reward_delayed), axis=-1)\n","    \n","    xs_train = xs[:, :n_episodes_train]\n","    ys_train = ys[:, :n_episodes_train]\n","    xs_test = xs[:, n_episodes_train:]\n","    ys_test = ys[:, n_episodes_train:]\n","    \n","    n_actions = xs.shape[-1]# - 1  # -1 because of the delayed reward \n","    n_trials_per_session = xs.shape[0] \n","    n_sessions = xs_train.shape[1]\n","    \n","    dataset_train = rnn_utils_haiku.DatasetRNN(xs_train, ys_train)\n","    dataset_test = rnn_utils_haiku.DatasetRNN(xs_test, ys_test)\n","    \n","    experiment_list_train = None\n","    experiment_list_test = None\n","\n","else:\n","  raise NotImplementedError(\n","      (f'dataset_type {dataset_type} not implemented. '\n","       'Please select from drop-down list.'))"]},{"cell_type":"markdown","metadata":{"id":"t-wfvf86jgoU"},"source":["## Train SINDy on actual data and replace agent's update rule with SINDy update rule\n","\n","The target equation for SINDy with forgetting is:\n","\n","$$Q_\\text{k+1}=(1-f)Q_\\text{k} + f Q_0 - \\alpha (1-f) c Q_\\text{k} - \\alpha f Q_0 c + \\alpha c r$$\n","\n","For the values $f=0.1$, $\\alpha=0.25$, $Q_0=0.5$ this gives the constants\n","$$Q_\\text{k+1}=0.9 Q_\\text{k} + 0.05 - 0.225 c Q_\\text{k} -  0.0125 c + 0.25 c r$$"]},{"cell_type":"code","execution_count":6,"metadata":{"metadata":{}},"outputs":[],"source":["get_choices = True\n","poly_order = 3\n","threshold = 0.01\n","dt = 1\n","\n","custom_lib_functions = [\n","    # sub-library which is always included    \n","    lambda q,c,r: q,\n","    lambda q,c,r: r,\n","    lambda q,c,r: np.power(q, 2),\n","    lambda q,c,r: q*r,\n","    lambda q,c,r: np.power(r, 2),\n","    # sub-library if the possible action was chosen\n","    lambda q,c,r: c,\n","    lambda q,c,r: c*q,\n","    lambda q,c,r: c*r,\n","    lambda q,c,r: c*np.power(q, 2),\n","    lambda q,c,r: c*q*r,\n","    lambda q,c,r: c*np.power(r, 2),\n","]\n","\n","custom_lib_names = [\n","    # part library which is always included\n","    lambda q,c,r: f'{q}',\n","    lambda q,c,r: f'{r}',\n","    lambda q,c,r: f'{q}^2',\n","    lambda q,c,r: f'{q}*{r}',\n","    lambda q,c,r: f'{r}^2',\n","    # part library if the possible action was chosen\n","    lambda q,c,r: f'{c}',\n","    lambda q,c,r: f'{c}*{q}',\n","    lambda q,c,r: f'{c}*{r}',\n","    lambda q,c,r: f'{c}*{q}^2',\n","    lambda q,c,r: f'{c}*{q}*{r}',\n","    lambda q,c,r: f'{c}*{r}^2',\n","]\n","\n","# solution library for f=0.5, alpha=0.25, Q_init=0.5\n","# solution_lib = ps.CustomLibrary(\n","#     library_functions=[lambda q,c,r: 0.5*q + 0.25 - 0.125*c*q - 0.0675*c + 0.25*c*r],\n","#     function_names=[lambda q,c,r: f'0.5*q + 0.25 - 0.125*c*q - 0.0675*c + 0.25*c*r'],\n","#     include_bias=False,\n","#     library_ensemble=False,\n","# )"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40135,"status":"ok","timestamp":1703171428064,"user":{"displayName":"Daniel W","userId":"06430346412716090550"},"user_tz":-60},"id":"WgenO280YtSk","metadata":{},"outputId":"46beeeb1-ed36-493b-fd59-659c2bb98cee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of Q-Values is: (440, 200, 1)\n","Shape of control parameters is: (440, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n"," Iteration ... |y - Xw|^2 ...  a * |w|_2 ...      |w|_0 ... Total error: |y - Xw|^2 + a * |w|_2\n","         0 ... 3.0906e-02 ... 1.0495e-01 ...          6 ... 1.3586e-01\n","         1 ... 1.5466e-06 ... 1.0521e-01 ...          6 ... 1.0521e-01\n","(q)[k+1] = 1.000 q[k] + -0.125 q[k] c[k] + 0.083 c[k] r[k] + -0.125 q[k] c[k]^2 + 0.083 c[k]^2 r[k] + 0.083 c[k] r[k]^2\n"]}],"source":["#@title Fit SINDy to actual dataset\n","# library = custom_lib  # custom_lib, poly_lib, solution_lib\n","ensemble = False\n","library_ensemble = False\n","\n","# library_datasindy = ps.CustomLibrary(\n","#     library_functions=custom_lib_functions,\n","#     function_names=custom_lib_names,\n","#     include_bias=True,\n","# )\n","\n","library_datasindy = ps.PolynomialLibrary(poly_order)\n","\n","experiment_list_datasindy = None\n","\n","if dataset_type == 'synt':\n","    x_train, control, feature_names = make_sindy_data(experiment_list_train, agent, get_choices=get_choices)\n","\n","    datasindy = ps.SINDy(\n","        optimizer=ps.STLSQ(threshold=threshold, verbose=True, alpha=0.1),\n","        feature_library=library_datasindy,\n","        discrete_time=True,\n","        feature_names=feature_names,\n","    )\n","    datasindy.fit(x_train, t=dt, u=control, ensemble=ensemble, library_ensemble=library_ensemble, multiple_trajectories=True)\n","    datasindy.print()\n","\n","    # set new sindy update rule and synthesize new dataset\n","    if not get_choices:\n","        update_rule_datasindy = lambda q, choice, reward: datasindy.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n","    else:\n","        update_rule_datasindy = lambda q, choice, reward: datasindy.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n","    \n","    datasindyagent = AgentSindy(alpha=0, beta=gen_beta, n_actions=n_actions)\n","    datasindyagent.set_update_rule(update_rule_datasindy)\n","\n","    # _, experiment_list_datasindy = bandits.create_dataset(datasindyagent, environment, n_trials_per_session, n_sessions)"]},{"cell_type":"markdown","metadata":{},"source":["For the values $f=0.5$, $\\alpha=0.25$ and $Q_0=0.5$ the discovered model should be equal to\n","$$Q_\\text{k+1}=0.9 Q_\\text{k} + 0.05 - 0.225 c Q_\\text{k} -  0.0125 c + 0.25 c r$$"]},{"cell_type":"markdown","metadata":{"id":"5aYKermb0BJe"},"source":["## Fit a hybrid RNN and train SINDy on RNN dynamics"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"lkBYYdpXcO59","metadata":{}},"outputs":[],"source":["#@title Set up Hybrid RNN.\n","\n","#@markdown Is the model recurrent (ie can it see the hidden state from the previous step)\n","use_hidden_state = False  #@param ['True', 'False']\n","\n","#@markdown Is the model recurrent (ie can it see the hidden state from the previous step)\n","use_previous_values = False  #@param ['True', 'False']\n","\n","#@markdown If True, learn a value for the forgetting term\n","fit_forget = False  #@param ['True', 'False']\n","\n","#@markdown Learn a reward-independent term that depends on past choices.\n","habit_weight = \"0\"  #@param [0, 1]\n","habit_weight = float(habit_weight)\n","\n","value_weight = 1.  # This is needed for it to be doing RL\n","\n","rnn_rl_params = {\n","    's': use_hidden_state,\n","    'o': use_previous_values,\n","    'fit_forget': fit_forget,\n","    'forget': 0.,\n","    'w_h': habit_weight,\n","    'w_v': value_weight}\n","network_params = {'n_actions': n_actions, 'hidden_size': 16}\n","\n","def make_hybrnn():\n","  # model = hybrnn.BiRNN(rl_params=rnn_rl_params, network_params=network_params)\n","  model = hybrnn.BiRNN(rl_params=rnn_rl_params, network_params=network_params)\n","  return model\n","\n","optimizer_rnn = optax.adam(learning_rate=1e-3)"]},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95493,"status":"ok","timestamp":1703173698779,"user":{"displayName":"Daniel W","userId":"06430346412716090550"},"user_tz":-60},"id":"catb-Attg4XL","metadata":{},"outputId":"67fc93c8-c51c-41bb-87ba-963fee64c698"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the hybrid RNN...\n"]},{"name":"stderr","output_type":"stream","text":["An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"]},{"name":"stdout","output_type":"stream","text":["Step 500 of 500; Loss: 0.6171510; Time: 6.2s)\n","Model not yet converged - Running more steps of gradient descent. Time elapsed = 1e-05s.\n","Step 500 of 500; Loss: 0.6169332; Time: 5.9s)\n","Model not yet converged (convergence_value = 0.0003529045) - Running more steps of gradient descent. Time elapsed = 2e-05s.\n","Step 500 of 500; Loss: 0.6169112; Time: 5.8s)\n","Model not yet converged (convergence_value = 3.574733e-05) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n","Step 500 of 500; Loss: 0.6169151; Time: 5.9s)\n","Model Converged! Time elapsed = 2e-05s.\n","Training took 24.53 seconds.\n"]}],"source":["train = True\n","load = False  # only relevant if train is True --> Determines whether to load trained parameters and continue training or start new training\n","\n","import time\n","start_time = time.time()\n","\n","# params_path = 'params/params_rnn_forget_f01.pkl'\n","params_path = 'params/params_rnn_forget_b3.pkl'\n","\n","if train:\n","  if load:\n","    with open(params_path, 'rb') as f:\n","      rnn_params = pickle.load(f)\n","    opt_state = rnn_params[1]\n","    rnn_params = rnn_params[0]\n","    print('Loaded parameters.')\n","  else:\n","    opt_state = None\n","    rnn_params = None\n","\n","  # with jax.disable_jit():\n","  #@title Fit the hybrid RNN\n","  print('Training the hybrid RNN...')\n","  rnn_params, opt_state, _ = rnn_utils.fit_model(\n","      model_fun=make_hybrnn,\n","      dataset=dataset_train,\n","      optimizer=optimizer_rnn,\n","      optimizer_state=opt_state,\n","      model_params=rnn_params,\n","      loss_fun='categorical',  # penalized_categorical, categorical\n","      convergence_thresh=1e-5,\n","      n_steps_max=10000,\n","  )\n","\n","  # save trained parameters\n","  params = (rnn_params, opt_state)\n","  with open(params_path, 'wb') as f:\n","    pickle.dump(params, f)\n","    \n","else:\n","  # load trained parameters\n","  with open(params_path, 'rb') as f:\n","    rnn_params = pickle.load(f)[0]\n","  print('Loaded parameters.')\n","  \n","print(f'Training took {time.time()-start_time:.2f} seconds.')"]},{"cell_type":"code","execution_count":10,"metadata":{"cellView":"form","id":"3e5500Whxah7","metadata":{}},"outputs":[],"source":["#@title Synthesize a dataset using the fitted network\n","hybrnn_agent = AgentNetwork_VisibleState(make_hybrnn, rnn_params, habit=habit_weight==1, n_actions=n_actions)\n","dataset_hybrnn, experiment_list_hybrnn = bandits.create_dataset(hybrnn_agent, environment, n_trials_per_session, int(n_sessions*1e-1))"]},{"cell_type":"code","execution_count":11,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63609,"status":"ok","timestamp":1703173770410,"user":{"displayName":"Daniel W","userId":"06430346412716090550"},"user_tz":-60},"id":"19B6ACNt1MhT","metadata":{},"outputId":"98b0ba77-336f-490c-da6f-5c1555a3da77"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of Q-Values is: (44, 200, 1)\n","Shape of control parameters is: (44, 200, 2)\n","Feature names are: ['q', 'c', 'r']\n","(q)[k+1] = -0.009 1 + -0.378 q[k] + -0.045 c[k] + -0.221 r[k] + -0.208 q[k]^2 + 0.136 q[k] c[k] + 0.009 q[k] r[k] + -0.045 c[k]^2 + 0.356 c[k] r[k] + -0.221 r[k]^2 + 0.514 q[k]^3 + 0.796 q[k]^2 c[k] + 0.050 q[k]^2 r[k] + 0.136 q[k] c[k]^2 + 0.009 q[k] r[k]^2 + -0.045 c[k]^3 + 0.356 c[k]^2 r[k] + 0.356 c[k] r[k]^2 + -0.221 r[k]^3\n","Sparsity index: 0.6\n"]}],"source":["#@title Fit SINDy to RNN data and synthesize new dataset\n","\n","threshold = 0.015\n","\n","x_train, control, feature_names = make_sindy_data(experiment_list_hybrnn, hybrnn_agent, get_choices=True)\n","# x_train, control, feature_names = make_sindy_data(experiment_list_train, agent, get_choices=get_choices)\n","# scale q-values between 0 and 1 for more realistic dynamics\n","# x_max = np.max(np.stack(x_train, axis=0))\n","# x_min = np.min(np.stack(x_train, axis=0))\n","# print(f'Dataset characteristics: max={x_max}, min={x_min}')\n","# x_train = [(x - x_min) / (x_max - x_min) for x in x_train]\n","\n","# library_rnnsindy = ps.CustomLibrary(\n","#     library_functions=custom_lib_functions,\n","#     function_names=custom_lib_names,\n","#     include_bias=True,\n","# )\n","\n","library_rnnsindy = ps.PolynomialLibrary(poly_order)\n","\n","rnnsindy = ps.SINDy(\n","    optimizer=ps.STLSQ(threshold=threshold, verbose=False, alpha=0.1),\n","    feature_library=library_rnnsindy,\n","    discrete_time=True,\n","    feature_names=feature_names,\n",")\n","\n","rnnsindy.fit(x_train, t=dt, u=control, ensemble=True, library_ensemble=False, multiple_trajectories=True)\n","rnnsindy.print()\n","sparsity_index = np.sum(rnnsindy.coefficients() < threshold) / rnnsindy.coefficients().size\n","print(f'Sparsity index: {sparsity_index}')\n","\n","if not get_choices:\n","    update_rule_rnnsindy = lambda q, choice, reward: rnnsindy.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n","else:\n","    update_rule_rnnsindy = lambda q, choice, reward: rnnsindy.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n","\n","rnnsindyagent = AgentSindy(alpha=0, beta=1, n_actions=n_actions)\n","rnnsindyagent.set_update_rule(update_rule_rnnsindy)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# # POST-PROCESSING\n","\n","# # fit beta parameter of softmax by fitting on choice probability of the RNN by simple grid search\n","\n","# # number of observed points\n","# n_points = 100\n","\n","# # epochs\n","# epoch = 0\n","# epochs_max = 100\n","# session_id = 0\n","\n","# # get choice probabilities of the RNN\n","# qs, choice_probs_rnn = get_q(experiment_list_hybrnn[session_id], hybrnn_agent)\n","\n","# # set prior for beta parameter; x_max seems to be a good starting point\n","# # beta_range = np.linspace(x_max-1, x_max+1, n_points)\n","# beta_range = np.linspace(1, 10, n_points)\n","\n","# # get choice probabilities of the SINDy agent for each beta in beta_range\n","# choice_probs_sindy = np.zeros((len(beta_range), len(choice_probs_rnn), n_actions))\n","# for i, beta in enumerate(beta_range):\n","#     sindy_agent = AgentSindy(alpha=0, beta=beta, n_actions=n_actions)\n","#     sindy_agent.set_update_rule(update_rule_rnnsindy)\n","#     _, choice_probs_sindy_beta = get_q(experiment_list_hybrnn[session_id], sindy_agent)\n","    \n","#     # add choice probabilities to choice_probs_sindy\n","#     choice_probs_sindy[i, :, :] = choice_probs_sindy_beta\n","    \n","# # get best beta value by minimizing the error between choice probabilities of the RNN and the SINDy agent\n","# errors = np.zeros(len(beta_range))\n","# for i in range(len(beta_range)):\n","#     errors[i] = np.sum(np.abs(choice_probs_rnn - choice_probs_sindy[i]))\n","\n","# # get right beta value\n","# beta = beta_range[np.argmin(errors)]\n","\n","# # plot error plot with best beta value in title\n","# plt.plot(beta_range, errors)\n","# plt.title(f'Error plot with best beta={beta}')\n","# plt.xlabel('Beta')\n","# plt.ylabel('MAE')\n","# plt.show()\n","\n","# print(f'Setting up SINDy agent with beta={beta}...')\n","\n","# rnnsindyagent = AgentSindy(alpha=0, beta=beta, n_actions=n_actions)\n","# rnnsindyagent.set_update_rule(update_rule_rnnsindy)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# perform experiments with the SINDy agent\n","_, experiment_list_rnnsindy = bandits.create_dataset(rnnsindyagent, environment, n_trials_per_session, 1)#n_sessions)"]},{"cell_type":"markdown","metadata":{"id":"Onnp7JiYjuh4"},"source":["## Analysis"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["label_test, label_hybrnn, label_datasindy, label_rnnsindy = 'Test', 'Hybrid RNN', 'SINDy', 'RNN+SINDy'\n","\n","labels = [\n","    label_test, \n","    label_hybrnn, \n","    # label_datasindy, \n","    label_rnnsindy,\n","    ]\n","\n","save_fig = True\n","session_id = 0\n","binary = not non_binary_reward"]},{"cell_type":"code","execution_count":21,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2283,"status":"ok","timestamp":1703173772685,"user":{"displayName":"Daniel W","userId":"06430346412716090550"},"user_tz":-60},"id":"N03qCFykWOY1","outputId":"8e9ef522-efba-4009-dcae-6a695ac62f00"},"outputs":[],"source":["#@title Plot action similarities.\n","\n","# plot reward probabilities\n","choices = experiment_list_test[session_id].choices\n","rewards = experiment_list_test[session_id].rewards\n","\n","reward_probs = np.stack([experiment_list_test[session_id].timeseries[:, i] for i in range(n_actions)], axis=0)\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices, \n","    rewards=rewards, \n","    timeseries=reward_probs,\n","    timeseries_name='', # 'Reward Probabilities'\n","    # labels=[f'Reward Prob {a}' for a in range(n_actions)],\n","    color=['tab:purple', 'tab:cyan'],\n","    binary=binary,\n","    )\n","plt.show() if not save_fig else plt.savefig('plots/reward_probs.png', dpi=1000)\n","\n","# plot evolution of Q-Values for same reward and choice trial data\n","\n","list_probs = []\n","list_qs = []\n","if label_test in labels:\n","    qs_test, probs_test = get_q(experiment_list_test[session_id], agent)\n","    list_probs.append(np.expand_dims(probs_test, 0))\n","    list_qs.append(np.expand_dims(qs_test, 0))\n","if label_hybrnn in labels:\n","    qs_hybrnn, probs_hybrnn = get_q(experiment_list_test[session_id], hybrnn_agent)\n","    list_probs.append(np.expand_dims(probs_hybrnn, 0))\n","    list_qs.append(np.expand_dims(qs_hybrnn, 0))\n","if label_datasindy in labels:\n","    qs_datasindy, probs_datasindy = get_q(experiment_list_test[session_id], datasindyagent)\n","    list_probs.append(np.expand_dims(probs_datasindy, 0))\n","    list_qs.append(np.expand_dims(qs_datasindy, 0))\n","if label_rnnsindy in labels:\n","    qs_rnnsindy, probs_rnnsindy = get_q(experiment_list_test[session_id], rnnsindyagent)\n","    list_probs.append(np.expand_dims(probs_rnnsindy, 0))\n","    list_qs.append(np.expand_dims(qs_rnnsindy, 0))\n","\n","# colors = ['cyan', 'magenta', 'yellow', 'grey']\n","colors = ['tab:blue', 'tab:orange', 'tab:pink', 'tab:gray']\n","\n","# concatenate all choice probs and q-values\n","probs = np.concatenate(list_probs, axis=0)\n","qs = np.concatenate(list_qs, axis=0)\n","\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=probs[:, :, 0],\n","    timeseries_name='Probability',\n","    title='Given and estimated choice probabilities in a two-armed bandit task',\n","    labels=labels,\n","    color=colors,\n","    binary=binary,\n","    axis_info=True,\n","    )\n","plt.show() if not save_fig else plt.savefig('plots/choice_probs.png', dpi=1000)\n","\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=qs[:, :, 0],\n","    timeseries_name='', # 'Q-Values',\n","    # labels=labels,\n","    color=colors,\n","    binary=binary,\n","    )\n","plt.show() if not save_fig else plt.savefig('plots/q_values.png', dpi=1000)\n","\n","def normalize(x, axis=1):\n","    x_min = np.min(x, keepdims=True, axis=axis)\n","    x_max = np.max(x, keepdims=True, axis=axis)\n","    return (x - x_min) / (x_max - x_min)\n","\n","qs_norm = normalize(qs)\n","\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=qs_norm[:, :, 0],\n","    timeseries_name='', # 'norm. Q-Values',\n","    # labels=labels,\n","    color=colors,\n","    binary=binary,\n","    )\n","plt.show() if not save_fig else plt.savefig('plots/q_values_norm.png', dpi=1000)\n","\n","dqs_trials = np.diff(qs, axis=1)\n","# for i in range(1, len(qs)):\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=dqs_trials[:, :, 0],\n","    timeseries_name='', # 'dQ/dt',\n","    # labels=labels,\n","    color=colors,\n","    binary=binary,\n",")\n","# plt.legend()\n","plt.show() if not save_fig else plt.savefig('plots/dq_dt.png', dpi=1000)\n","\n","norm_dqs_trials = normalize(dqs_trials)\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=norm_dqs_trials[:, :, 0],\n","    timeseries_name='', # 'norm. dQ/dt',\n","    # labels=labels,\n","    color=colors,\n","    binary=binary,\n",")\n","# plt.legend()\n","plt.show() if not save_fig else plt.savefig('plots/dq_dt.png', dpi=1000)\n","\n","dqs_arms = np.diff(qs, axis=2)\n","norm_dqs_arms = normalize(dqs_arms)\n","# dqs_arms /= np.max(np.abs(dqs_arms), axis=(1, 2), keepdims=True)\n","bandits.plot_session(\n","    compare=True,\n","    choices=choices,\n","    rewards=rewards,\n","    timeseries=norm_dqs_arms,\n","    timeseries_name='', # 'dQ/dArm',\n","    # # labels=labels,\n","    color=colors,\n","    binary=binary,\n",")\n","plt.show() if not save_fig else plt.savefig('plots/dq_darm.png', dpi=1000)\n","\n","# Calculate reward rates\n","# Plot proportion Leftward Choices over difference in reward prob (left vs right)\n","\n","# experiment_list = []\n","# if label_test in labels:\n","#     print('Test dataset:')\n","#     bandits.show_total_reward_rate(experiment_list_test)\n","#     bandits.show_valuemetric(experiment_list_test, label=label_test)\n","#     experiment_list.append(experiment_list_test)\n","# if label_hybrnn in labels:\n","#     print('RNN dataset:')\n","#     bandits.show_total_reward_rate(experiment_list_hybrnn)\n","#     bandits.show_valuemetric(experiment_list_hybrnn, label=label_hybrnn)\n","#     experiment_list.append(experiment_list_hybrnn)\n","# if label_datasindy in labels:\n","#     print('Data SINDy dataset:')\n","#     bandits.show_total_reward_rate(experiment_list_datasindy)\n","#     bandits.show_valuemetric(experiment_list_datasindy, label=label_datasindy)\n","#     experiment_list.append(experiment_list_datasindy)\n","# if label_rnnsindy in labels:\n","#     print('RNN SINDy dataset:')\n","#     bandits.show_total_reward_rate(experiment_list_rnnsindy)\n","#     bandits.show_valuemetric(experiment_list_rnnsindy, label=label_rnnsindy)\n","#     experiment_list.append(experiment_list_rnnsindy)\n","# plt.legend()\n","# plt.show()\n","\n","# # plot choice similarity over history\n","# plt.figure()\n","# plot_action_similarity_to_history(experiment_list, n_steps_back=16, labels=labels, bbox_to_anchor=(1, 1))\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Groundtruth coefficients:\n","[0.0, 1, -0.0, 0, 0, -0.25, 0, 0, 0.25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","raw SINDy coefficients:\n","[-0.01 -0.38 -0.05 -0.22 -0.21  0.14  0.01 -0.05  0.36 -0.22  0.51  0.8\n","  0.05  0.14  0.    0.01 -0.05  0.36  0.36 -0.22]\n","post-processed SINDy coefficients:\n","[ 0.   -0.38 -0.14 -0.66 -0.21  0.27  0.02  0.    1.07  0.    0.51  0.8\n","  0.05  0.    0.    0.    0.    0.    0.    0.  ]\n","Correctly recovered terms: 8/15\n","['term', 'groundtruth', 'sindy']\n","['1', 0.0, 0.0]\n","['q', 1, -0.38]\n","['c', -0.0, -0.14]\n","['r', 0, -0.66]\n","['q^2', 0, -0.21]\n","['q c', -0.25, 0.27]\n","['q r', 0, 0.02]\n","['c^2', 0, 0.0]\n","['c r', 0.25, 1.07]\n","['r^2', 0, 0.0]\n","['q^3', 0, 0.51]\n","['q^2 c', 0, 0.8]\n","['q^2 r', 0, 0.05]\n","['q c^2', 0, 0.0]\n","['q c r', 0, 0.0]\n","['q r^2', 0, 0.0]\n","['c^3', 0, 0.0]\n","['c^2 r', 0, 0.0]\n","['c r^2', 0, 0.0]\n","['r^3', 0, 0.0]\n"]}],"source":["# check for correctly recovered parameters\n","# groundtruth equation: Q_k+1 = f Q_init + (1-f) Q_k - f * alpha * Q_init * c - (1-f) * alpha * c * Q_k + alpha * c * r\n","# equations = ['1','q','c','r','q^2','q c','q r','c^2','c r','r^2','q^3','q^2 c','q^2 r','q c^2','q c r','q r^2','c^3','c^2 r','c r^2','r^3']\n","# similar = [0, 1, 2, 3, 4, 5, 6, 2, 7, 3, 8, 9, 10, 5, ]\n","# groundtruth coefficients for model w/ and w/o forgetting; for polynomial order 3 library\n","groundtruth_coeffs = [forgetting_rate * 0.5, 1-forgetting_rate, -0.5*gen_alpha*forgetting_rate, 0, 0, -(1-forgetting_rate)*gen_alpha, 0, 0, gen_alpha, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","print('Groundtruth coefficients:')\n","print(groundtruth_coeffs)\n","sindy_coeffs = rnnsindy.coefficients().reshape(-1).copy()\n","print('raw SINDy coefficients:')\n","print(np.round(sindy_coeffs, 2))\n","# post-processing of sindy coefficients\n","# sum up all coefficients that encode the same term if their values are equal\n","equal_terms = {'c': ['c', 'c^2', 'c^3'], 'r': ['r', 'r^2', 'r^3'], 'c r': ['c r', 'c^2 r', 'c r^2'], 'q c': ['q c', 'q c^2'], 'q r': ['q r', 'q r^2']}\n","sindy_terms = rnnsindy.get_feature_names()\n","if not non_binary_reward:\n","    for term in equal_terms.keys():\n","        for equal_term in equal_terms[term]:\n","            if equal_term in sindy_terms:\n","                if equal_term != term:\n","                    sindy_coeffs[sindy_terms.index(term)] += sindy_coeffs[sindy_terms.index(equal_term)]\n","                    sindy_coeffs[sindy_terms.index(equal_term)] = 0\n","\n","print('post-processed SINDy coefficients:')\n","# filter all remaining coeffs which are lower than threshold\n","sindy_coeffs[np.abs(sindy_coeffs) < threshold] = 0\n","print(np.round(sindy_coeffs, 2))\n","\n","# get number of correctly recovered terms\n","correct_terms = 0\n","for i in range(len(sindy_terms)):\n","    if groundtruth_coeffs[i] != 0 and sindy_coeffs[i] != 0:\n","        correct_terms += 1\n","    elif groundtruth_coeffs[i] == 0 and sindy_coeffs[i] == 0:\n","        correct_terms += 1\n","\n","# substract the equal terms\n","substracted_terms = 0\n","if not non_binary_reward:\n","    for term in equal_terms.keys():\n","        if term in sindy_terms:\n","            substracted_terms += 1\n","print(f'Correctly recovered terms: {correct_terms-substracted_terms}/{len(sindy_terms)-substracted_terms}')\n","\n","# list_coeffs = [[sindy_terms[i], groundtruth_coeffs[i], np.round(sindy_coeffs[i], 2), np.round(rnnsindy.coefficients().reshape(-1)[i], 2)] for i in range(len(sindy_terms))]\n","# list_features = ['term', 'groundtruth', 'sindy', 'sindy_orig']\n","\n","list_coeffs = [[sindy_terms[i], groundtruth_coeffs[i], np.round(sindy_coeffs[i], 2)] for i in range(len(sindy_terms))]\n","list_features = ['term', 'groundtruth', 'sindy']\n","\n","print(list_features)\n","for i in range(len(list_coeffs)):\n","    print(list_coeffs[i])\n","    \n","import pandas as pd\n","\n","pd.DataFrame(list_coeffs, columns=list_features).to_csv('recovered_coeffs_beta'+str(gen_beta)+'.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# plot q-value update with old vs new q-values and reward as color\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m experiment_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 16\u001b[0m     qs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[43m[\u001b[49m\u001b[43mexperiment_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msession\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_sessions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m     choices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([experiment_dict[l][session]\u001b[38;5;241m.\u001b[39mchoices \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([experiment_dict[l][session]\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# plot q-value update with old vs new q-values and reward as color\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m experiment_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 16\u001b[0m     qs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43mexperiment_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msession\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mq \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m     choices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([experiment_dict[l][session]\u001b[38;5;241m.\u001b[39mchoices \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m     rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([experiment_dict[l][session]\u001b[38;5;241m.\u001b[39mrewards \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_sessions)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def normalize(x, axis=1):\n","    x_min = np.min(x) #np.min(x, keepdims=True, axis=axis)\n","    x_max = np.max(x) #np.max(x, keepdims=True, axis=axis)\n","    return (x - x_min) / (x_max - x_min)\n","\n","# take qs_norm as q-values\n","experiment_dict = {\n","    label_test: experiment_list_test,\n","    label_hybrnn: experiment_list_hybrnn, \n","    # label_datasindy: experiment_list_datasindy, \n","    label_rnnsindy: experiment_list_rnnsindy,\n","    }\n","\n","# plot q-value update with old vs new q-values and reward as color\n","for l in experiment_dict.keys():\n","    qs = np.stack([experiment_dict[l][session].q for session in range(n_sessions)], axis=1)\n","    choices = np.stack([experiment_dict[l][session].choices for session in range(n_sessions)], axis=1)\n","    rewards = np.stack([experiment_dict[l][session].rewards for session in range(n_sessions)], axis=1)\n","    \n","    qs = normalize(qs, axis=0)\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    for session in range(n_sessions):\n","        ax.plot(np.linspace(-10, 10), np.linspace(-10, 10), 'grey', linewidth=0.5) \n","        for arm in range(n_actions):\n","            q_old = qs[:-1, session, arm]\n","            q_new = qs[1:, session, arm]\n","            ax.scatter(q_old, q_new, c=experiment_dict[l][session].rewards[:-1], alpha=.05, s=1)\n","    # set colorbar\n","    # cbar = plt.colorbar(ax.scatter([], [], c=[], alpha=1, s=1))\n","    # cbar.set_label('Reward')\n","    q_min = np.min(qs)\n","    q_max = np.max(qs)\n","    ax.set_ylim(q_min, q_max)\n","    ax.set_xlim(q_min, q_max)\n","    ax.set_xticks(np.linspace(q_min, q_max, 5))\n","    ax.set_yticks(np.linspace(q_min, q_max, 5))\n","    ax.set_xticklabels(['']*5)\n","    ax.set_yticklabels(['']*5)\n","    plt.rc('grid', color='grey')\n","    plt.grid()\n","    # plt.title(l)\n","    # plt.xlabel('Old Q-Values')\n","    # plt.ylabel('New Q-Values')\n","    plt.show() if not save_fig else plt.savefig(f'plots/q_value_update_{l}.png', dpi=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNwCLLvTmMqZJNfKuTxnPyw","collapsed_sections":["LwfT57-uJIt9","Eq7jeg9mIx-f","Ca6uMC-Pglux","5aYKermb0BJe"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
