{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo:\n",
    "# print statements for the class require verbose=True in the class\n",
    "# Sklearn estimator\n",
    "# SINDY class is not quite right! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import libraries\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from typing import Callable, Tuple, Iterable, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import pickle\n",
    "\n",
    "# deepmind related libraries\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import pysindy as ps\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# RL libraries\n",
    "sys.path.append('resources')  # add source directoy to path\n",
    "from resources import bandits, disrnn, hybrnn, hybrnn_forget, plotting, rat_data, rnn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title make update rule of Q-/SINDyNetwork-Agents adjustable and make values of RNN-Agent visible\n",
    "\n",
    "class AgentQuadQ(bandits.AgentQ):\n",
    "  \n",
    "  def __init__(\n",
    "      self,\n",
    "      alpha: float=0.2,\n",
    "      beta: float=3.,\n",
    "      n_actions: int=2,\n",
    "      forgetting_rate: float=0.,\n",
    "      perseveration_bias: float=0.,\n",
    "      ):\n",
    "    super().__init__(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n",
    "  \n",
    "  def update(self,\n",
    "            choice: int,\n",
    "            reward: float):\n",
    "    \"\"\"Update the agent after one step of the task.\n",
    "\n",
    "    Args:\n",
    "      choice: The choice made by the agent. 0 or 1\n",
    "      reward: The reward received by the agent. 0 or 1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Decay q-values toward the initial value.\n",
    "    self._q = (1-self._forgetting_rate) * self._q + self._forgetting_rate * self._q_init\n",
    "\n",
    "    # Update chosen q for chosen action with observed reward.\n",
    "    self._q[choice] = self._q[choice] - self._alpha * self._q[choice]**2 + self._alpha * reward\n",
    "\n",
    "\n",
    "class AgentSindy(bandits.AgentQ):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      alpha: float=0.2,\n",
    "      beta: float=3.,\n",
    "      n_actions: int=2,\n",
    "      forgetting_rate: float=0.,\n",
    "      perservation_bias: float=0.,):\n",
    "    super().__init__(alpha, beta, n_actions, forgetting_rate, perservation_bias)\n",
    "\n",
    "    self._update_rule = lambda q, choice, reward: (1 - self._alpha) * q[choice] + self._alpha * reward\n",
    "    self._update_rule_formula = None\n",
    "\n",
    "  def set_update_rule(self, update_rule: callable, update_rule_formula: str=None):\n",
    "    self._update_rule=update_rule\n",
    "    self._update_rule_formula=update_rule_formula\n",
    "\n",
    "  @property\n",
    "  def update_rule(self):\n",
    "    if self._update_rule_formula is not None:\n",
    "      return self._update_rule_formula\n",
    "    else:\n",
    "      return f'{self._update_rule}'\n",
    "\n",
    "  def update(self, choice: int, reward: int):\n",
    "\n",
    "    for c in range(self._n_actions):\n",
    "      self._q[c] = self._update_rule(self._q[c], int(c==choice), reward)\n",
    "\n",
    "\n",
    "class AgentNetwork_VisibleState(bandits.AgentNetwork):\n",
    "\n",
    "  def __init__(self,\n",
    "               make_network: Callable[[], hk.RNNCore],\n",
    "               params: hk.Params,\n",
    "               n_actions: int = 2,\n",
    "               state_to_numpy: bool = False,\n",
    "               habit=False):\n",
    "    super().__init__(make_network=make_network, params=params, n_actions=n_actions, state_to_numpy=state_to_numpy)\n",
    "    self.habit = habit\n",
    "\n",
    "  @property\n",
    "  def q(self):\n",
    "    if self.habit:\n",
    "      return self._state[2], self._state[3]\n",
    "    else:\n",
    "      return self._state[3].reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_agents = {\n",
    "    'basic': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: bandits.AgentQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias),\n",
    "    'quad_q': lambda alpha, beta, n_actions, forgetting_rate, perseveration_bias: AgentQuadQ(alpha, beta, n_actions, forgetting_rate, perseveration_bias)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCreator:\n",
    "    def __init__(self, dataset_type, agent_dict):\n",
    "        self.dataset_type = dataset_type\n",
    "        self.agent_dict = agent_dict\n",
    "\n",
    "    def create_dataset(self):\n",
    "        if self.dataset_type == 'synt':\n",
    "            self.setup_synthetic_data()\n",
    "            self.dataset_train, self.experiment_list_train = self.generate_data()\n",
    "            self.dataset_test, self.experiment_list_test = self.generate_data()\n",
    "        \n",
    "        elif self.dataset_type == 'real':\n",
    "            raise NotImplementedError('Real data setup not implemented yet.')\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(f'dataset_type {self.dataset_type} not implemented. Please select from drop-down list.')\n",
    "\n",
    "    def setup_synthetic_data(self):\n",
    "        # Define agent parameters\n",
    "        agent_kw = 'basic'  # ['basic', 'quad_q']\n",
    "        gen_alpha = 0.25\n",
    "        gen_beta = 5\n",
    "        forgetting_rate = 0.1\n",
    "        perseveration_bias = 0.0\n",
    "        \n",
    "        # Define environment parameters\n",
    "        non_binary_reward = False\n",
    "        self.n_actions = 2\n",
    "        sigma = 0.1\n",
    "        \n",
    "        # Define experiment parameters\n",
    "        self.n_trials_per_session = 200\n",
    "        self.n_sessions = 220\n",
    "        \n",
    "        # Setup environment and agent\n",
    "        self.environment = bandits.EnvironmentBanditsDrift(sigma=sigma, n_actions=self.n_actions, non_binary_rewards=non_binary_reward)\n",
    "        self.agent = self.agent_dict[agent_kw](gen_alpha, gen_beta, self.n_actions, forgetting_rate, perseveration_bias)\n",
    "    \n",
    "    def setup_real_data(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def generate_data(self):\n",
    "        return bandits.create_dataset(\n",
    "            agent=self.agent,\n",
    "            environment=self.environment,\n",
    "            n_trials_per_session=self.n_trials_per_session,\n",
    "            n_sessions=self.n_sessions\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetCreator(dataset_type='synt', agent_dict=dict_agents)\n",
    "data.create_dataset()\n",
    "n_actions = data.n_actions\n",
    "agent = data.agent\n",
    "environment = data.environment\n",
    "n_trials_per_session = data.n_trials_per_session\n",
    "n_sessions = data.n_sessions\n",
    "\n",
    "dataset_train, experiment_list_train = data.dataset_train, data.experiment_list_train\n",
    "dataset_test, experiment_list_test = data.dataset_test, data.experiment_list_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRNN:\n",
    "    def __init__(self, use_hidden_state=False, use_previous_values=False, fit_forget=False, habit_weight=0.0, value_weight=1.0, n_actions=2, hidden_size=16):\n",
    "        self.use_hidden_state = use_hidden_state\n",
    "        self.use_previous_values = use_previous_values\n",
    "        self.fit_forget = fit_forget\n",
    "        self.habit_weight = float(habit_weight)\n",
    "        self.value_weight = value_weight\n",
    "        self.n_actions = n_actions\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Set up the RNN parameters\n",
    "        self.rnn_rl_params = {\n",
    "            's': self.use_hidden_state,\n",
    "            'o': self.use_previous_values,\n",
    "            'fit_forget': self.fit_forget,\n",
    "            'forget': 0.,\n",
    "            'w_h': self.habit_weight,\n",
    "            'w_v': self.value_weight\n",
    "        }\n",
    "        self.network_params = {\n",
    "            'n_actions': self.n_actions,\n",
    "            'hidden_size': self.hidden_size\n",
    "        }\n",
    "        \n",
    "    def make_hybrnn(self):\n",
    "        return hybrnn_forget.BiRNN(rl_params=self.rnn_rl_params, network_params=self.network_params)\n",
    "    \n",
    "    def get_make_hybrnn(self):\n",
    "        return self.make_hybrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "habit_weight=0.0 # used in Sindy RNN\n",
    "rnn = HybridRNN(habit_weight)\n",
    "optimizer_rnn = optax.adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTrainer:\n",
    "    def __init__(self, params_path, train=True, load=False, loss_function='categorical'):\n",
    "        self.params_path = params_path\n",
    "        self.train = train\n",
    "        self.load = load\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optax.adam(learning_rate=1e-3)\n",
    "        self.rnn_params = None\n",
    "        self.opt_state = None\n",
    "\n",
    "    def load_parameters(self):\n",
    "        try:\n",
    "            with open(self.params_path, 'rb') as f:\n",
    "                saved_params = pickle.load(f)\n",
    "            self.rnn_params, self.opt_state = saved_params[0], saved_params[1]\n",
    "            print('Loaded parameters.')\n",
    "        except FileNotFoundError:\n",
    "            print('No parameters found to load.')\n",
    "\n",
    "    def save_parameters(self):\n",
    "        with open(self.params_path, 'wb') as f:\n",
    "            pickle.dump((self.rnn_params, self.opt_state), f)\n",
    "        print('Parameters saved.')\n",
    "\n",
    "    def train_model(self, dataset_train, n_steps_max=10000, convergence_thresh=1e-5):\n",
    "        if self.train:\n",
    "            if self.load:\n",
    "                self.load_parameters()\n",
    "            else:\n",
    "                self.rnn_params, self.opt_state = None, None\n",
    "\n",
    "            print('Training the hybrid RNN...')\n",
    "            self.rnn_params, self.opt_state, _ = rnn_utils.fit_model(\n",
    "                model_fun=rnn.make_hybrnn,\n",
    "                dataset=dataset_train,\n",
    "                optimizer=self.optimizer,\n",
    "                optimizer_state=self.opt_state,\n",
    "                model_params=self.rnn_params,\n",
    "                loss_fun=self.loss_function,\n",
    "                convergence_thresh=convergence_thresh,\n",
    "                n_steps_max=n_steps_max\n",
    "            )\n",
    "\n",
    "            self.save_parameters()\n",
    "\n",
    "    def execute(self, dataset_train):\n",
    "        if self.train:\n",
    "            self.train_model(dataset_train)\n",
    "        else:\n",
    "            self.load_parameters()\n",
    "    \n",
    "    def get_rnn_params(self):\n",
    "        return self.rnn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the hybrid RNN...\n",
      "Step 500 of 500; Loss: 0.5304508; Time: 11.1s)\n",
      "Model not yet converged - Running more steps of gradient descent. Time elapsed = 2e-05s.\n",
      "Step 500 of 500; Loss: 0.5302345; Time: 14.0s)\n",
      "Model not yet converged (convergence_value = 0.0004077763) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n",
      "Step 500 of 500; Loss: 0.5301611; Time: 10.5s)\n",
      "Model not yet converged (convergence_value = 0.000138379) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n",
      "Step 500 of 500; Loss: 0.5300407; Time: 10.5s)\n",
      "Model not yet converged (convergence_value = 0.0002271034) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n",
      "Step 500 of 500; Loss: 0.5297045; Time: 11.7s)\n",
      "Model not yet converged (convergence_value = 0.0006343471) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n",
      "Step 500 of 500; Loss: 0.5247840; Time: 11.6s)\n",
      "Model not yet converged (convergence_value = 0.009289108) - Running more steps of gradient descent. Time elapsed = 3e-05s.\n",
      "Step 500 of 500; Loss: 0.5242616; Time: 11.8s)\n",
      "Model not yet converged (convergence_value = 0.0009955233) - Running more steps of gradient descent. Time elapsed = 7e-05s.\n",
      "Step 500 of 500; Loss: 0.5242454; Time: 12.2s)\n",
      "Model not yet converged (convergence_value = 3.092438e-05) - Running more steps of gradient descent. Time elapsed = 4e-05s.\n",
      "Step 500 of 500; Loss: 0.5242456; Time: 10.4s)\n",
      "Model Converged! Time elapsed = 2e-05s.\n",
      "Parameters saved.\n"
     ]
    }
   ],
   "source": [
    "params_path = 'params/params_rnn_forget_f01_b5.pkl'\n",
    "rnn_train = RNNTrainer(params_path=params_path, train=True, load=False)\n",
    "rnn_train.execute(dataset_train)\n",
    "rnn_params = rnn_train.get_rnn_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sindy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sindy_data(\n",
    "    dataset,\n",
    "    agent: bandits.AgentQ,\n",
    "    sessions=-1,\n",
    "    get_choices=True,\n",
    "    # keep_sessions=False,\n",
    "    ):\n",
    "\n",
    "  # Get training data for SINDy\n",
    "  # put all relevant signals in x_train\n",
    "\n",
    "  if not isinstance(sessions, Iterable) and sessions == -1:\n",
    "    # use all sessions\n",
    "    sessions = np.arange(len(dataset))\n",
    "  else:\n",
    "    # use only the specified sessions\n",
    "    sessions = np.array(sessions)\n",
    "    \n",
    "  if get_choices:\n",
    "    n_control = 2\n",
    "  else:\n",
    "    n_control = 1\n",
    "  \n",
    "  # if keep_sessions:\n",
    "  #   # concatenate all sessions along the trial dimensinon -> shape: (n_trials, n_sessions, n_features)\n",
    "  #   choices = np.expand_dims(np.stack([dataset[i].choices for i in sessions], axis=1), -1)\n",
    "  #   rewards = np.expand_dims(np.stack([dataset[i].rewards for i in sessions], axis=1), -1)\n",
    "  #   qs = np.stack([dataset[i].q for i in sessions], axis=1)\n",
    "  # else:\n",
    "  # concatenate all sessions along the trial dimensinon -> shape: (n_trials*n_sessions, n_features)\n",
    "  # choices = np.expand_dims(np.concatenate([dataset[i].choices for i in sessions], axis=0), -1)\n",
    "  # rewards = np.expand_dims(np.concatenate([dataset[i].rewards for i in sessions], axis=0), -1)\n",
    "  # qs = np.concatenate([dataset[i].q for i in sessions], axis=0)\n",
    "  \n",
    "  choices = np.stack([dataset[i].choices for i in sessions], axis=0)\n",
    "  rewards = np.stack([dataset[i].rewards for i in sessions], axis=0)\n",
    "  qs = np.stack([dataset[i].q for i in sessions], axis=0)\n",
    "  \n",
    "  if not get_choices:\n",
    "    raise NotImplementedError('Only get_choices=True is implemented right now.')\n",
    "    n_sessions = qs.shape[0]\n",
    "    n_trials = qs.shape[1]*qs.shape[2]\n",
    "    qs_all = np.zeros((n_sessions, n_trials))\n",
    "    r_all = np.zeros((n_sessions, n_trials))\n",
    "    c_all = None\n",
    "    # concatenate the data of all arms into one array for more training data\n",
    "    index_end_last_arm = 0\n",
    "    for index_arm in range(agent._n_actions):\n",
    "      index = np.where(choices==index_arm)[0]\n",
    "      r_all[index_end_last_arm:index_end_last_arm+len(index)] = rewards[index]\n",
    "      qs_all[index_end_last_arm:index_end_last_arm+len(index)] = qs[index, index_arm].reshape(-1, 1)\n",
    "      index_end_last_arm += len(index)\n",
    "  else:\n",
    "    choices_oh = np.zeros((len(sessions), choices.shape[1], agent._n_actions))\n",
    "    for sess in sessions:\n",
    "      # one-hot encode choices\n",
    "      choices_oh[sess] = np.eye(agent._n_actions)[choices[sess]]\n",
    "      # add choices as control parameter; no sorting required then\n",
    "      # qs_all = np.concatenate([qs[sess, :, i] for i in range(agent._n_actions)], axis=1)\n",
    "      # c_all = np.concatenate([choices[:, sess, i] for i in range(agent._n_actions)], axis=1)\n",
    "      # r_all = np.concatenate([rewards for _ in range(agent._n_actions)], axis=1)\n",
    "      # concatenate all qs values of one sessions along the trial dimension\n",
    "      qs_all = np.concatenate([np.stack([np.expand_dims(qs_sess[:, i], axis=-1) for i in range(agent._n_actions)], axis=0) for qs_sess in qs], axis=0)\n",
    "      c_all = np.concatenate([np.stack([c_sess[:, i] for i in range(agent._n_actions)], axis=0) for c_sess in choices_oh], axis=0)\n",
    "      r_all = np.concatenate([np.stack([r_sess for _ in range(agent._n_actions)], axis=0) for r_sess in rewards], axis=0)\n",
    "  \n",
    "  # get observed dynamics\n",
    "  x_train = qs_all\n",
    "  feature_names = ['q']\n",
    "\n",
    "  # get control\n",
    "  control_names = []\n",
    "  control = np.zeros((*x_train.shape[:-1], n_control))\n",
    "  if get_choices:\n",
    "    control[:, :, 0] = c_all\n",
    "    control_names += ['c']\n",
    "  control[:, :, n_control-1] = r_all\n",
    "  control_names += ['r']\n",
    "  \n",
    "  feature_names += control_names\n",
    "  \n",
    "  print(f'Shape of Q-Values is: {x_train.shape}')\n",
    "  print(f'Shape of control parameters is: {control.shape}')\n",
    "  print(f'Feature names are: {feature_names}')\n",
    "  \n",
    "  # make x_train and control sequences instead of arrays\n",
    "  x_train = [x_train_sess for x_train_sess in x_train]\n",
    "  control = [control_sess for control_sess in control]\n",
    " \n",
    "  return x_train, control, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not needed anymore! Check SINDY class!!!\n",
    "\n",
    "class SINDyTrainerGroundTruth:\n",
    "    def __init__(self, library, dataset_type='synt', threshold=0.01, dt=1, ensemble=False, library_ensemble=False, get_choices=True):\n",
    "        self.library = library\n",
    "        self.dataset_type = dataset_type\n",
    "        self.threshold = threshold\n",
    "        self.dt = dt\n",
    "        self.ensemble = ensemble\n",
    "        self.library_ensemble = library_ensemble\n",
    "        self.get_choices = get_choices\n",
    "\n",
    "    def fit(self, experiment_list_train, agent, custom_lib_functions=None, custom_lib_names=None, poly_order=3):\n",
    "        if self.library == 'custom_lib':\n",
    "            library_datasindy = ps.CustomLibrary(\n",
    "                library_functions=custom_lib_functions,\n",
    "                function_names=custom_lib_names,\n",
    "                include_bias=True\n",
    "            )\n",
    "        elif self.library == 'poly_lib':\n",
    "            library_datasindy = ps.PolynomialLibrary(poly_order)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported library type\")\n",
    "\n",
    "        if self.dataset_type == 'synt':\n",
    "            x_train, control, feature_names = make_sindy_data(experiment_list_train, agent, get_choices=self.get_choices)\n",
    "\n",
    "            optimizer = ps.STLSQ(threshold=self.threshold, verbose=True, alpha=0.1)\n",
    "            datasindy = ps.SINDy(\n",
    "                optimizer=optimizer,\n",
    "                feature_library=library_datasindy,\n",
    "                discrete_time=True,\n",
    "                feature_names=feature_names\n",
    "            )\n",
    "            datasindy.fit(x_train, t=self.dt, u=control, ensemble=self.ensemble, library_ensemble=self.library_ensemble, multiple_trajectories=True)\n",
    "            datasindy.print()\n",
    "\n",
    "            return datasindy\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported dataset type\")\n",
    "        \n",
    "    def update_rule(self, datasindy, get_choices):\n",
    "        if not get_choices:\n",
    "            return lambda q, choice, reward: datasindy.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n",
    "        else:\n",
    "            return lambda q, choice, reward: datasindy.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q-Values is: (440, 200, 1)\n",
      "Shape of control parameters is: (440, 200, 2)\n",
      "Feature names are: ['q', 'c', 'r']\n",
      " Iteration ... |y - Xw|^2 ...  a * |w|_2 ...      |w|_0 ... Total error: |y - Xw|^2 + a * |w|_2\n",
      "         0 ... 7.1269e+00 ... 8.3683e-02 ...          9 ... 7.2106e+00\n",
      "         1 ... 1.3575e+00 ... 8.7696e-02 ...          8 ... 1.4452e+00\n",
      "         2 ... 3.6690e-01 ... 8.6887e-02 ...          8 ... 4.5379e-01\n",
      "(q)[k+1] = 0.047 1 + 0.903 q[k] + -107786162.664 q[k] c[k] + 753016385.140 c[k] r[k] + 0.010 q[k]^3 + 107786162.416 q[k] c[k]^2 + -1535317856.596 c[k]^2 r[k] + 782301471.706 c[k] r[k]^2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,\n",
       "      feature_library=PolynomialLibrary(degree=3),\n",
       "      feature_names=[&#x27;q&#x27;, &#x27;c&#x27;, &#x27;r&#x27;],\n",
       "      optimizer=STLSQ(alpha=0.1, threshold=0.01, verbose=True))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SINDy<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,\n",
       "      feature_library=PolynomialLibrary(degree=3),\n",
       "      feature_names=[&#x27;q&#x27;, &#x27;c&#x27;, &#x27;r&#x27;],\n",
       "      optimizer=STLSQ(alpha=0.1, threshold=0.01, verbose=True))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">feature_library: PolynomialLibrary</label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialLibrary(degree=3)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">PolynomialLibrary</label><div class=\"sk-toggleable__content fitted\"><pre>PolynomialLibrary(degree=3)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">optimizer: STLSQ</label><div class=\"sk-toggleable__content fitted\"><pre>STLSQ(alpha=0.1, threshold=0.01, verbose=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">STLSQ</label><div class=\"sk-toggleable__content fitted\"><pre>STLSQ(alpha=0.1, threshold=0.01, verbose=True)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SINDy(differentiation_method=FiniteDifference(axis=-2), discrete_time=True,\n",
       "      feature_library=PolynomialLibrary(degree=3),\n",
       "      feature_names=['q', 'c', 'r'],\n",
       "      optimizer=STLSQ(alpha=0.1, threshold=0.01, verbose=True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = SINDyTrainerGroundTruth(library='poly_lib')\n",
    "rnnsindyagent = AgentSindy(alpha=0, beta=1, n_actions=2)\n",
    "rnnsindyagent.set_update_rule(trainer.update_rule)\n",
    "trainer.fit(experiment_list_train, agent=agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN agent for Sindy\n",
    "\n",
    "hybrnn_agent = AgentNetwork_VisibleState(rnn.get_make_hybrnn(), rnn_params, habit=habit_weight==1, n_actions=n_actions)\n",
    "\n",
    "dataset_hybrnn, experiment_list_hybrnn = bandits.create_dataset(hybrnn_agent, environment, n_trials_per_session, int(n_sessions*1e0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not needed anymore! Check SINDY class!!!\n",
    "class SINDyRNN:\n",
    "    def __init__(self, experiment_list, hybrnn_agent, get_choices, poly_order, dt, n_actions, custom_lib_functions=None, custom_lib_names=None, threshold=0.015):\n",
    "        self.experiment_list = experiment_list\n",
    "        self.hybrnn_agent = hybrnn_agent\n",
    "        self.get_choices = get_choices\n",
    "        self.poly_order = poly_order\n",
    "        self.dt = dt\n",
    "        self.n_actions = n_actions\n",
    "        self.threshold = threshold\n",
    "        self.custom_lib_functions = custom_lib_functions\n",
    "        self.custom_lib_names = custom_lib_names\n",
    "\n",
    "    def make_sindy_data(self):\n",
    "        # Assuming make_sindy_data is a function defined elsewhere\n",
    "        return make_sindy_data(self.experiment_list, self.hybrnn_agent, get_choices=self.get_choices)\n",
    "\n",
    "    def fit(self):\n",
    "        x_train, control, feature_names = self.make_sindy_data()\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "        # Scale q-values between 0 and 1 for more realistic dynamics\n",
    "        self.x_max = np.max(np.stack(x_train, axis=0))\n",
    "        self.x_min = np.min(np.stack(x_train, axis=0))\n",
    "        print(f'Dataset characteristics: max={self.x_max}, min={self.x_min}')\n",
    "        x_train = [(x - self.x_min) / (self.x_max - self.x_min) for x in x_train]\n",
    "\n",
    "        if self.custom_lib_functions and self.custom_lib_names:\n",
    "            library_rnnsindy = ps.CustomLibrary(\n",
    "                library_functions=self.custom_lib_functions,\n",
    "                function_names=self.custom_lib_names,\n",
    "                include_bias=True,\n",
    "            )\n",
    "        else:\n",
    "            library_rnnsindy = ps.PolynomialLibrary(self.poly_order)\n",
    "\n",
    "        self.rnnsindy = ps.SINDy(\n",
    "            optimizer=ps.STLSQ(threshold=self.threshold, verbose=False, alpha=0.1),\n",
    "            feature_library=library_rnnsindy,\n",
    "            discrete_time=True,\n",
    "            feature_names=self.feature_names,\n",
    "        )\n",
    "\n",
    "        self.rnnsindy.fit(x_train, t=self.dt, u=control, ensemble=True, library_ensemble=False, multiple_trajectories=True)\n",
    "        self.rnnsindy.print()\n",
    "        self.sparsity_index = np.sum(self.rnnsindy.coefficients() < self.threshold) / self.rnnsindy.coefficients().size\n",
    "        \n",
    "\n",
    "        if not self.get_choices:\n",
    "            update_rule_rnnsindy = lambda q, choice, reward: self.rnnsindy.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n",
    "        else:\n",
    "            update_rule_rnnsindy = lambda q, choice, reward: self.rnnsindy.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n",
    "\n",
    "        self.rnnsindyagent = AgentSindy(alpha=0, beta=1, n_actions=self.n_actions)\n",
    "        self.rnnsindyagent.set_update_rule(update_rule_rnnsindy)\n",
    "\n",
    "    def get_rnnsindyagent(self):\n",
    "        return self.rnnsindyagent\n",
    "\n",
    "    def get_sparsity_index(self):\n",
    "        return self.sparsity_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q-Values is: (440, 200, 1)\n",
      "Shape of control parameters is: (440, 200, 2)\n",
      "Feature names are: ['q', 'c', 'r']\n",
      "Dataset characteristics: max=2.6803841590881348, min=-1.2137874364852905\n",
      "(q)[k+1] = 0.043 1 + 0.922 q[k] + -1795847285.974 c[k] + -0.022 q[k]^2 + -201448.414 q[k] c[k] + -6583929.778 q[k] r[k] + -1797956774.496 c[k]^2 + -2641056717.121 c[k] r[k] + 0.013 q[k]^3 + 0.004 q[k]^2 c[k] + -0.001 q[k]^2 r[k] + 201448.171 q[k] c[k]^2 + 6583929.779 q[k] r[k]^2 + 3593804060.423 c[k]^3 + 5205082427.721 c[k]^2 r[k] + -2564025710.275 c[k] r[k]^2\n",
      "Sparsity index: 0.7\n"
     ]
    }
   ],
   "source": [
    "get_choices = True\n",
    "poly_order = 3\n",
    "threshold = 0.01\n",
    "dt = 1\n",
    "\n",
    "\n",
    "sindy_rnn = SINDyRNN(\n",
    "    experiment_list=experiment_list_hybrnn,\n",
    "    hybrnn_agent=hybrnn_agent,\n",
    "    get_choices=get_choices,\n",
    "    poly_order=poly_order,\n",
    "    dt=dt,\n",
    "    n_actions=n_actions\n",
    ")\n",
    "\n",
    "sindy_rnn.fit()\n",
    "rnnsindyagent = sindy_rnn.get_rnnsindyagent()\n",
    "sparsity_index = sindy_rnn.get_sparsity_index()\n",
    "\n",
    "print(f'Sparsity index: {sparsity_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sindy Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SINDY:\n",
    "    def __init__(self, experiment_list, agent, library_config=None, scaling=True,\n",
    "                 get_choices=True, dt=1, threshold=0.01, n_actions=None,\n",
    "                 ensemble=False, library_ensemble=False):\n",
    "        self.experiment_list = experiment_list\n",
    "        self.agent = agent\n",
    "        \n",
    "        # Ensure library_config is a dictionary\n",
    "        if library_config is None:\n",
    "            self.library_config = {'type': 'poly_lib', 'poly_order': 3}\n",
    "        elif isinstance(library_config, dict):\n",
    "            self.library_config = library_config\n",
    "        else:\n",
    "            raise ValueError(\"library_config must be a dictionary\")\n",
    "        \n",
    "        self.scaling = scaling\n",
    "        self.get_choices = get_choices\n",
    "        self.poly_order = poly_order\n",
    "        self.dt = dt\n",
    "        self.threshold = threshold\n",
    "        self.n_actions = n_actions\n",
    "        self.ensemble = ensemble\n",
    "        self.library_ensemble = library_ensemble\n",
    "\n",
    "    def make_sindy_data(self):\n",
    "        # Assuming make_sindy_data is a function defined elsewhere\n",
    "        return make_sindy_data(self.experiment_list, self.agent, get_choices=self.get_choices)\n",
    "\n",
    "    def fit(self):\n",
    "        x_train, control, feature_names = self.make_sindy_data()\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "        # Library selection\n",
    "        library_type = self.library_config.get('type')\n",
    "        if library_type == 'custom_lib':\n",
    "            custom_lib_functions = self.library_config.get('custom_lib_functions')\n",
    "            custom_lib_names = self.library_config.get('custom_lib_names')\n",
    "            library_sindy = ps.CustomLibrary(\n",
    "                library_functions=custom_lib_functions,\n",
    "                function_names=custom_lib_names,\n",
    "                include_bias=True\n",
    "            )\n",
    "        \n",
    "        elif library_type == 'poly_lib':\n",
    "            poly_order = self.library_config.get('poly_order')\n",
    "            library_sindy = ps.PolynomialLibrary(poly_order)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unsupported library type\")\n",
    "\n",
    "        # Data scaling for RNN SINDy\n",
    "        if self.scaling == True:\n",
    "            self.x_max = np.max(np.stack(x_train, axis=0))\n",
    "            self.x_min = np.min(np.stack(x_train, axis=0))\n",
    "            x_train = [(x - self.x_min) / (self.x_max - self.x_min) for x in x_train]\n",
    "\n",
    "        optimizer = ps.STLSQ(threshold=self.threshold, verbose=True, alpha=0.1)\n",
    "        self.model = ps.SINDy(\n",
    "            optimizer=optimizer,\n",
    "            feature_library=library_sindy,\n",
    "            discrete_time=True,\n",
    "            feature_names=feature_names\n",
    "        )\n",
    "        self.model.fit(x_train, t=self.dt, u=control, ensemble=self.ensemble, library_ensemble=self.library_ensemble, multiple_trajectories=True)\n",
    "        self.model.print()\n",
    "\n",
    "        if not self.get_choices:\n",
    "            update_rule_rnnsindy = lambda q, choice, reward: self.rnnsindy.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n",
    "        else:\n",
    "            update_rule_rnnsindy = lambda q, choice, reward: self.rnnsindy.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n",
    "            \n",
    "        self.rnnsindyagent = AgentSindy(alpha=0, beta=1, n_actions=self.n_actions)\n",
    "        self.rnnsindyagent.set_update_rule(update_rule_rnnsindy) \n",
    "\n",
    "    def update_rule(self, q, choice, reward):\n",
    "        if not self.get_choices:\n",
    "            return self.model.simulate(q[choice], t=2, u=np.array(reward).reshape(1, 1))[-1]\n",
    "        else:\n",
    "            return self.model.simulate(q, t=2, u=np.array([choice, reward]).reshape(1, 2))[-1]\n",
    "\n",
    "    def get_rnnsindyagent(self):\n",
    "        return self.rnnsindyagent\n",
    "\n",
    "    def get_sparsity_index(self):\n",
    "        if self.model:\n",
    "            return np.sum(self.model.coefficients() < self.threshold) / self.model.coefficients().size\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q-Values is: (440, 200, 1)\n",
      "Shape of control parameters is: (440, 200, 2)\n",
      "Feature names are: ['q', 'c', 'r']\n",
      " Iteration ... |y - Xw|^2 ...  a * |w|_2 ...      |w|_0 ... Total error: |y - Xw|^2 + a * |w|_2\n",
      "         0 ... 7.1269e+00 ... 8.3683e-02 ...          9 ... 7.2106e+00\n",
      "         1 ... 1.3575e+00 ... 8.7696e-02 ...          8 ... 1.4452e+00\n",
      "         2 ... 3.6690e-01 ... 8.6887e-02 ...          8 ... 4.5379e-01\n",
      "(q)[k+1] = 0.047 1 + 0.903 q[k] + -107786162.664 q[k] c[k] + 753016385.140 c[k] r[k] + 0.010 q[k]^3 + 107786162.416 q[k] c[k]^2 + -1535317856.596 c[k]^2 r[k] + 782301471.706 c[k] r[k]^2\n"
     ]
    }
   ],
   "source": [
    "# library_config = {\n",
    "#     'type': 'custom_lib',\n",
    "#     'custom_lib_functions':\n",
    "#     'custom_lib_names': \n",
    "# }\n",
    "\n",
    "lib_config = {\n",
    "    'type': 'poly_lib',\n",
    "    'poly_order': 3\n",
    "}\n",
    "\n",
    "trainer = SINDY(get_choices=True, dt=1, library_config=lib_config, n_actions=2, experiment_list=experiment_list_train, agent=agent, scaling=False)\n",
    "rnnsindyagent = AgentSindy(alpha=0, beta=1, n_actions=2)\n",
    "rnnsindyagent.set_update_rule(trainer.update_rule)\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SINDYRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Q-Values is: (440, 200, 1)\n",
      "Shape of control parameters is: (440, 200, 2)\n",
      "Feature names are: ['q', 'c', 'r']\n",
      " Iteration ... |y - Xw|^2 ...  a * |w|_2 ...      |w|_0 ... Total error: |y - Xw|^2 + a * |w|_2\n",
      "         0 ... 2.8895e+00 ... 9.1328e-02 ...         11 ... 2.9809e+00\n",
      "         1 ... 7.6341e-01 ... 8.9726e-02 ...         10 ... 8.5314e-01\n",
      "         2 ... 7.6109e-01 ... 8.9789e-02 ...         10 ... 8.5088e-01\n",
      "(q)[k+1] = 0.044 1 + 0.912 q[k] + -0.016 c[k] + -0.119 q[k] c[k] + -0.016 c[k]^2 + 0.108 c[k] r[k] + -0.119 q[k] c[k]^2 + -0.016 c[k]^3 + 0.108 c[k]^2 r[k] + 0.108 c[k] r[k]^2\n",
      "Sparsity index: 0.75\n"
     ]
    }
   ],
   "source": [
    "get_choices = True\n",
    "poly_order = 3\n",
    "threshold = 0.01\n",
    "dt = 1\n",
    "n_actions = 2\n",
    "\n",
    "sindy_rnn = SINDY(\n",
    "    experiment_list=experiment_list_hybrnn,\n",
    "    agent=hybrnn_agent,\n",
    "    get_choices=get_choices,\n",
    "    dt=dt,\n",
    "    n_actions=n_actions,\n",
    "    scaling=True\n",
    "\n",
    ")\n",
    "\n",
    "sindy_rnn.fit()\n",
    "rnnsindyagent = sindy_rnn.get_rnnsindyagent()\n",
    "sparsity_index = sindy_rnn.get_sparsity_index()\n",
    "\n",
    "print(f'Sparsity index: {sparsity_index}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labrotation-daniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
